{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcff0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9109425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd582475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "785f874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = list(paths.list_images('data/Caltech101/001'))\n",
    "#image_paths = list(paths.list_images('data/cars_side-view'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "278fcc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 1133.62it/s]\n",
      "<ipython-input-23-b8270de6310a>:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  data = np.array(data)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for img_path in tqdm(image_paths):\n",
    "    label = img_path.split(os.path.sep)[-2]\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    data.append(img)\n",
    "    labels.append(label)\n",
    "    if len(labels) > 5000:\n",
    "        break\n",
    "    \n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4dc09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2586fca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lb = LabelEncoder()\n",
    "labels = lb.fit_transform(labels)\n",
    "print(f\"Total Number of Classes: {len(lb.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838a64bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 123})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d9a63af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train examples: (720,)\n",
      "x_test examples: (80,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# divide the data into train and test set\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data, labels, test_size=0.1, stratify=labels, random_state=42)\n",
    "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d1601e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {'size': 64, 'channels': 3, 'classes': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e9ace3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6191a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((dataset_config['size'], dataset_config['size'])),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((dataset_config['size'],dataset_config['size'])),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660fb4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BS = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=BS, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=BS, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eed5de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 32\n",
    "# custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels= None, transforms = None):\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.images[index][:]\n",
    "        \n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "            \n",
    "        \n",
    "        return (data, self.labels[index])\n",
    "        \n",
    "train_data = CustomDataset(x_train, y_train, train_transforms)\n",
    "test_data = CustomDataset(x_test, y_test, val_transform)       \n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BS, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=BS, shuffle=True, num_workers=4, drop_last=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7adf75",
   "metadata": {},
   "source": [
    "### --- Main --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8eb3b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "def gradients(y, x):\n",
    "    return autograd.grad(\n",
    "                outputs=y, inputs=x, retain_graph=True,\n",
    "                create_graph=True, grad_outputs=torch.ones_like(y), only_inputs=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffb061e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Cifar10(nn.Module):\n",
    "    def __init__(self, label = 'cifar10', image_size = dataset_config['size'], channel_num = dataset_config['channels'], kernel_num = 128, z_size=128):\n",
    "        # configurations\n",
    "        super().__init__()\n",
    "        self.label = label\n",
    "        self.image_size = image_size\n",
    "        self.channel_num = channel_num\n",
    "        self.kernel_num = kernel_num\n",
    "        self.z_size = z_size\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            self._conv(channel_num, kernel_num // 4),\n",
    "            self._conv(kernel_num // 4, kernel_num // 2),\n",
    "            self._conv(kernel_num // 2, kernel_num),\n",
    "        )\n",
    "\n",
    "        # encoded feature's size and volume\n",
    "\n",
    "        # q\n",
    "        self.q_mean = self._linear(self.feature_volume, z_size, relu=False)\n",
    "        self.q_logvar = self._linear(self.feature_volume, z_size, relu=False)\n",
    "\n",
    "        # projection\n",
    "        self.project = self._linear(z_size, self.feature_volume, relu=False)\n",
    "\n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            self._deconv(kernel_num, kernel_num // 2),\n",
    "            self._deconv(kernel_num // 2, kernel_num // 4),\n",
    "            self._deconv(kernel_num // 4, channel_num),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        # sample latent code z from q given x.\n",
    "        mean, logvar = self.q(encoded)\n",
    "        z = self.z(mean, logvar)\n",
    "        z_projected = self.project(z).view(\n",
    "            -1, self.kernel_num,\n",
    "            self.feature_size,\n",
    "            self.feature_size,\n",
    "        )\n",
    "\n",
    "        # reconstruct x from z\n",
    "        x_reconstructed = self.decoder(z_projected)\n",
    "\n",
    "        return x_reconstructed, mean, logvar\n",
    "    \n",
    "    def q(self, encoded):\n",
    "        unrolled = encoded.view(-1, self.feature_volume)\n",
    "        return self.q_mean(unrolled), self.q_logvar(unrolled)\n",
    "\n",
    "    def z(self, mean, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = (Variable(torch.randn(std.size())).to(device))\n",
    "        \n",
    "        return mean#eps.mul(std).add_(mean)\n",
    "    \n",
    "    \n",
    "    # ======\n",
    "    # Layers\n",
    "    # ======\n",
    "\n",
    "    def _conv(self, channel_size, kernel_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channel_size, kernel_num,\n",
    "                kernel_size=4, stride=2, padding=1,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(kernel_num),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _deconv(self, channel_num, kernel_num):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                channel_num, kernel_num,\n",
    "                kernel_size=4, stride=2, padding=1,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(kernel_num),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _linear(self, in_size, out_size, relu=True):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_size, out_size),\n",
    "            nn.ReLU(),\n",
    "        ) if relu else nn.Linear(in_size, out_size)\n",
    "\n",
    "model = VAE_Cifar10().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b12ac909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    MSE = (recon_x - x.view(-1,  dataset_config['channels'],dataset_config['size'],dataset_config['size'])) ** 2\n",
    "    MSE = MSE.sum(dim=(-1,-2,-3))\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=-1)\n",
    "\n",
    "    return MSE + 0.3 * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d3e7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar).mean(dim=0)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 2 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ad88685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).mean(dim=0).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch[:n].view(n,  dataset_config['channels'], dataset_config['size'], dataset_config['size'])[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28ecf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87e574b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/720 (0%)]\tLoss: 34.416878\n",
      "Train Epoch: 1 [64/720 (9%)]\tLoss: 32.253586\n",
      "Train Epoch: 1 [128/720 (17%)]\tLoss: 28.188232\n",
      "Train Epoch: 1 [192/720 (26%)]\tLoss: 28.446091\n",
      "Train Epoch: 1 [256/720 (35%)]\tLoss: 27.629402\n",
      "Train Epoch: 1 [320/720 (43%)]\tLoss: 25.524319\n",
      "Train Epoch: 1 [384/720 (52%)]\tLoss: 26.149231\n",
      "Train Epoch: 1 [448/720 (61%)]\tLoss: 25.002098\n",
      "Train Epoch: 1 [512/720 (70%)]\tLoss: 20.960619\n",
      "Train Epoch: 1 [576/720 (78%)]\tLoss: 25.569416\n",
      "Train Epoch: 1 [640/720 (87%)]\tLoss: 25.051151\n",
      "Train Epoch: 1 [352/720 (96%)]\tLoss: 25.144415\n",
      "====> Epoch: 1 Average loss: 26.3103\n",
      "====> Test set loss: 23.0203\n",
      "Train Epoch: 2 [0/720 (0%)]\tLoss: 19.983946\n",
      "Train Epoch: 2 [64/720 (9%)]\tLoss: 24.922157\n",
      "Train Epoch: 2 [128/720 (17%)]\tLoss: 18.742249\n",
      "Train Epoch: 2 [192/720 (26%)]\tLoss: 22.263584\n",
      "Train Epoch: 2 [256/720 (35%)]\tLoss: 21.157627\n",
      "Train Epoch: 2 [320/720 (43%)]\tLoss: 19.543890\n",
      "Train Epoch: 2 [384/720 (52%)]\tLoss: 17.565090\n",
      "Train Epoch: 2 [448/720 (61%)]\tLoss: 19.897469\n",
      "Train Epoch: 2 [512/720 (70%)]\tLoss: 18.592056\n",
      "Train Epoch: 2 [576/720 (78%)]\tLoss: 18.536390\n",
      "Train Epoch: 2 [640/720 (87%)]\tLoss: 17.924049\n",
      "Train Epoch: 2 [352/720 (96%)]\tLoss: 17.946079\n",
      "====> Epoch: 2 Average loss: 19.3380\n",
      "====> Test set loss: 19.1912\n",
      "Train Epoch: 3 [0/720 (0%)]\tLoss: 20.058346\n",
      "Train Epoch: 3 [64/720 (9%)]\tLoss: 18.105896\n",
      "Train Epoch: 3 [128/720 (17%)]\tLoss: 18.707260\n",
      "Train Epoch: 3 [192/720 (26%)]\tLoss: 16.241859\n",
      "Train Epoch: 3 [256/720 (35%)]\tLoss: 14.485415\n",
      "Train Epoch: 3 [320/720 (43%)]\tLoss: 17.686029\n",
      "Train Epoch: 3 [384/720 (52%)]\tLoss: 17.658773\n",
      "Train Epoch: 3 [448/720 (61%)]\tLoss: 16.847752\n",
      "Train Epoch: 3 [512/720 (70%)]\tLoss: 13.465954\n",
      "Train Epoch: 3 [576/720 (78%)]\tLoss: 16.140966\n",
      "Train Epoch: 3 [640/720 (87%)]\tLoss: 16.782473\n",
      "Train Epoch: 3 [352/720 (96%)]\tLoss: 18.272345\n",
      "====> Epoch: 3 Average loss: 16.8911\n",
      "====> Test set loss: 17.7870\n",
      "Train Epoch: 4 [0/720 (0%)]\tLoss: 18.054970\n",
      "Train Epoch: 4 [64/720 (9%)]\tLoss: 16.459747\n",
      "Train Epoch: 4 [128/720 (17%)]\tLoss: 14.526810\n",
      "Train Epoch: 4 [192/720 (26%)]\tLoss: 16.996271\n",
      "Train Epoch: 4 [256/720 (35%)]\tLoss: 15.820167\n",
      "Train Epoch: 4 [320/720 (43%)]\tLoss: 13.196145\n",
      "Train Epoch: 4 [384/720 (52%)]\tLoss: 17.356495\n",
      "Train Epoch: 4 [448/720 (61%)]\tLoss: 15.657635\n",
      "Train Epoch: 4 [512/720 (70%)]\tLoss: 15.601731\n",
      "Train Epoch: 4 [576/720 (78%)]\tLoss: 14.382683\n",
      "Train Epoch: 4 [640/720 (87%)]\tLoss: 15.188079\n",
      "Train Epoch: 4 [352/720 (96%)]\tLoss: 20.332438\n",
      "====> Epoch: 4 Average loss: 15.8511\n",
      "====> Test set loss: 17.1570\n",
      "Train Epoch: 5 [0/720 (0%)]\tLoss: 17.469116\n",
      "Train Epoch: 5 [64/720 (9%)]\tLoss: 14.931863\n",
      "Train Epoch: 5 [128/720 (17%)]\tLoss: 17.571575\n",
      "Train Epoch: 5 [192/720 (26%)]\tLoss: 15.087224\n",
      "Train Epoch: 5 [256/720 (35%)]\tLoss: 15.267580\n",
      "Train Epoch: 5 [320/720 (43%)]\tLoss: 16.086300\n",
      "Train Epoch: 5 [384/720 (52%)]\tLoss: 16.377443\n",
      "Train Epoch: 5 [448/720 (61%)]\tLoss: 13.214856\n",
      "Train Epoch: 5 [512/720 (70%)]\tLoss: 14.382360\n",
      "Train Epoch: 5 [576/720 (78%)]\tLoss: 13.410976\n",
      "Train Epoch: 5 [640/720 (87%)]\tLoss: 14.044985\n",
      "Train Epoch: 5 [352/720 (96%)]\tLoss: 13.149033\n",
      "====> Epoch: 5 Average loss: 15.2922\n",
      "====> Test set loss: 17.0207\n",
      "Train Epoch: 6 [0/720 (0%)]\tLoss: 15.074423\n",
      "Train Epoch: 6 [64/720 (9%)]\tLoss: 15.889357\n",
      "Train Epoch: 6 [128/720 (17%)]\tLoss: 17.190683\n",
      "Train Epoch: 6 [192/720 (26%)]\tLoss: 13.135467\n",
      "Train Epoch: 6 [256/720 (35%)]\tLoss: 16.824003\n",
      "Train Epoch: 6 [320/720 (43%)]\tLoss: 14.256673\n",
      "Train Epoch: 6 [384/720 (52%)]\tLoss: 16.328173\n",
      "Train Epoch: 6 [448/720 (61%)]\tLoss: 13.243867\n",
      "Train Epoch: 6 [512/720 (70%)]\tLoss: 14.570938\n",
      "Train Epoch: 6 [576/720 (78%)]\tLoss: 15.251764\n",
      "Train Epoch: 6 [640/720 (87%)]\tLoss: 14.637288\n",
      "Train Epoch: 6 [352/720 (96%)]\tLoss: 17.068359\n",
      "====> Epoch: 6 Average loss: 14.8895\n",
      "====> Test set loss: 16.5510\n",
      "Train Epoch: 7 [0/720 (0%)]\tLoss: 16.073685\n",
      "Train Epoch: 7 [64/720 (9%)]\tLoss: 12.097527\n",
      "Train Epoch: 7 [128/720 (17%)]\tLoss: 13.637926\n",
      "Train Epoch: 7 [192/720 (26%)]\tLoss: 14.204685\n",
      "Train Epoch: 7 [256/720 (35%)]\tLoss: 14.934903\n",
      "Train Epoch: 7 [320/720 (43%)]\tLoss: 13.515705\n",
      "Train Epoch: 7 [384/720 (52%)]\tLoss: 17.186777\n",
      "Train Epoch: 7 [448/720 (61%)]\tLoss: 13.797232\n",
      "Train Epoch: 7 [512/720 (70%)]\tLoss: 14.599401\n",
      "Train Epoch: 7 [576/720 (78%)]\tLoss: 15.663134\n",
      "Train Epoch: 7 [640/720 (87%)]\tLoss: 13.795297\n",
      "Train Epoch: 7 [352/720 (96%)]\tLoss: 13.674088\n",
      "====> Epoch: 7 Average loss: 14.6538\n",
      "====> Test set loss: 16.4849\n",
      "Train Epoch: 8 [0/720 (0%)]\tLoss: 15.531940\n",
      "Train Epoch: 8 [64/720 (9%)]\tLoss: 17.496178\n",
      "Train Epoch: 8 [128/720 (17%)]\tLoss: 13.749172\n",
      "Train Epoch: 8 [192/720 (26%)]\tLoss: 15.768909\n",
      "Train Epoch: 8 [256/720 (35%)]\tLoss: 14.264584\n",
      "Train Epoch: 8 [320/720 (43%)]\tLoss: 16.966461\n",
      "Train Epoch: 8 [384/720 (52%)]\tLoss: 15.800354\n",
      "Train Epoch: 8 [448/720 (61%)]\tLoss: 14.191229\n",
      "Train Epoch: 8 [512/720 (70%)]\tLoss: 15.188320\n",
      "Train Epoch: 8 [576/720 (78%)]\tLoss: 14.842216\n",
      "Train Epoch: 8 [640/720 (87%)]\tLoss: 13.874100\n",
      "Train Epoch: 8 [352/720 (96%)]\tLoss: 14.499396\n",
      "====> Epoch: 8 Average loss: 14.4522\n",
      "====> Test set loss: 16.1776\n",
      "Train Epoch: 9 [0/720 (0%)]\tLoss: 16.695345\n",
      "Train Epoch: 9 [64/720 (9%)]\tLoss: 15.067366\n",
      "Train Epoch: 9 [128/720 (17%)]\tLoss: 12.837631\n",
      "Train Epoch: 9 [192/720 (26%)]\tLoss: 13.156382\n",
      "Train Epoch: 9 [256/720 (35%)]\tLoss: 13.757545\n",
      "Train Epoch: 9 [320/720 (43%)]\tLoss: 13.848300\n",
      "Train Epoch: 9 [384/720 (52%)]\tLoss: 13.706907\n",
      "Train Epoch: 9 [448/720 (61%)]\tLoss: 12.689385\n",
      "Train Epoch: 9 [512/720 (70%)]\tLoss: 14.840288\n",
      "Train Epoch: 9 [576/720 (78%)]\tLoss: 16.070053\n",
      "Train Epoch: 9 [640/720 (87%)]\tLoss: 14.468346\n",
      "Train Epoch: 9 [352/720 (96%)]\tLoss: 11.466037\n",
      "====> Epoch: 9 Average loss: 14.1755\n",
      "====> Test set loss: 16.1221\n",
      "Train Epoch: 10 [0/720 (0%)]\tLoss: 14.053998\n",
      "Train Epoch: 10 [64/720 (9%)]\tLoss: 15.460992\n",
      "Train Epoch: 10 [128/720 (17%)]\tLoss: 14.056238\n",
      "Train Epoch: 10 [192/720 (26%)]\tLoss: 14.148833\n",
      "Train Epoch: 10 [256/720 (35%)]\tLoss: 13.180964\n",
      "Train Epoch: 10 [320/720 (43%)]\tLoss: 15.163535\n",
      "Train Epoch: 10 [384/720 (52%)]\tLoss: 13.540671\n",
      "Train Epoch: 10 [448/720 (61%)]\tLoss: 13.460340\n",
      "Train Epoch: 10 [512/720 (70%)]\tLoss: 11.207819\n",
      "Train Epoch: 10 [576/720 (78%)]\tLoss: 12.092587\n",
      "Train Epoch: 10 [640/720 (87%)]\tLoss: 13.192980\n",
      "Train Epoch: 10 [352/720 (96%)]\tLoss: 16.386703\n",
      "====> Epoch: 10 Average loss: 13.9835\n",
      "====> Test set loss: 15.8670\n",
      "Train Epoch: 11 [0/720 (0%)]\tLoss: 13.702323\n",
      "Train Epoch: 11 [64/720 (9%)]\tLoss: 14.089705\n",
      "Train Epoch: 11 [128/720 (17%)]\tLoss: 15.852407\n",
      "Train Epoch: 11 [192/720 (26%)]\tLoss: 11.995359\n",
      "Train Epoch: 11 [256/720 (35%)]\tLoss: 14.099300\n",
      "Train Epoch: 11 [320/720 (43%)]\tLoss: 14.545006\n",
      "Train Epoch: 11 [384/720 (52%)]\tLoss: 13.514853\n",
      "Train Epoch: 11 [448/720 (61%)]\tLoss: 14.250285\n",
      "Train Epoch: 11 [512/720 (70%)]\tLoss: 13.441618\n",
      "Train Epoch: 11 [576/720 (78%)]\tLoss: 14.853182\n",
      "Train Epoch: 11 [640/720 (87%)]\tLoss: 11.492087\n",
      "Train Epoch: 11 [352/720 (96%)]\tLoss: 15.480819\n",
      "====> Epoch: 11 Average loss: 13.7936\n",
      "====> Test set loss: 15.8376\n",
      "Train Epoch: 12 [0/720 (0%)]\tLoss: 14.929436\n",
      "Train Epoch: 12 [64/720 (9%)]\tLoss: 15.702524\n",
      "Train Epoch: 12 [128/720 (17%)]\tLoss: 12.779684\n",
      "Train Epoch: 12 [192/720 (26%)]\tLoss: 14.221049\n",
      "Train Epoch: 12 [256/720 (35%)]\tLoss: 15.771328\n",
      "Train Epoch: 12 [320/720 (43%)]\tLoss: 12.005474\n",
      "Train Epoch: 12 [384/720 (52%)]\tLoss: 13.155532\n",
      "Train Epoch: 12 [448/720 (61%)]\tLoss: 12.983715\n",
      "Train Epoch: 12 [512/720 (70%)]\tLoss: 14.586813\n",
      "Train Epoch: 12 [576/720 (78%)]\tLoss: 13.336924\n",
      "Train Epoch: 12 [640/720 (87%)]\tLoss: 14.694931\n",
      "Train Epoch: 12 [352/720 (96%)]\tLoss: 13.713733\n",
      "====> Epoch: 12 Average loss: 13.7208\n",
      "====> Test set loss: 15.7574\n",
      "Train Epoch: 13 [0/720 (0%)]\tLoss: 16.540907\n",
      "Train Epoch: 13 [64/720 (9%)]\tLoss: 13.752556\n",
      "Train Epoch: 13 [128/720 (17%)]\tLoss: 13.983497\n",
      "Train Epoch: 13 [192/720 (26%)]\tLoss: 13.836939\n",
      "Train Epoch: 13 [256/720 (35%)]\tLoss: 13.861907\n",
      "Train Epoch: 13 [320/720 (43%)]\tLoss: 13.603151\n",
      "Train Epoch: 13 [384/720 (52%)]\tLoss: 12.386152\n",
      "Train Epoch: 13 [448/720 (61%)]\tLoss: 14.231325\n",
      "Train Epoch: 13 [512/720 (70%)]\tLoss: 13.058308\n",
      "Train Epoch: 13 [576/720 (78%)]\tLoss: 13.495425\n",
      "Train Epoch: 13 [640/720 (87%)]\tLoss: 10.167152\n",
      "Train Epoch: 13 [352/720 (96%)]\tLoss: 14.271388\n",
      "====> Epoch: 13 Average loss: 13.6545\n",
      "====> Test set loss: 15.7556\n",
      "Train Epoch: 14 [0/720 (0%)]\tLoss: 12.599970\n",
      "Train Epoch: 14 [64/720 (9%)]\tLoss: 12.949154\n",
      "Train Epoch: 14 [128/720 (17%)]\tLoss: 15.161896\n",
      "Train Epoch: 14 [192/720 (26%)]\tLoss: 12.962920\n",
      "Train Epoch: 14 [256/720 (35%)]\tLoss: 12.328945\n",
      "Train Epoch: 14 [320/720 (43%)]\tLoss: 14.323825\n",
      "Train Epoch: 14 [384/720 (52%)]\tLoss: 14.051044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [448/720 (61%)]\tLoss: 14.935298\n",
      "Train Epoch: 14 [512/720 (70%)]\tLoss: 12.638957\n",
      "Train Epoch: 14 [576/720 (78%)]\tLoss: 14.630822\n",
      "Train Epoch: 14 [640/720 (87%)]\tLoss: 16.816351\n",
      "Train Epoch: 14 [352/720 (96%)]\tLoss: 11.630459\n",
      "====> Epoch: 14 Average loss: 13.5296\n",
      "====> Test set loss: 15.7205\n",
      "Train Epoch: 15 [0/720 (0%)]\tLoss: 14.008562\n",
      "Train Epoch: 15 [64/720 (9%)]\tLoss: 12.129624\n",
      "Train Epoch: 15 [128/720 (17%)]\tLoss: 13.126711\n",
      "Train Epoch: 15 [192/720 (26%)]\tLoss: 14.273884\n",
      "Train Epoch: 15 [256/720 (35%)]\tLoss: 12.579286\n",
      "Train Epoch: 15 [320/720 (43%)]\tLoss: 12.902699\n",
      "Train Epoch: 15 [384/720 (52%)]\tLoss: 12.563902\n",
      "Train Epoch: 15 [448/720 (61%)]\tLoss: 13.191581\n",
      "Train Epoch: 15 [512/720 (70%)]\tLoss: 15.257868\n",
      "Train Epoch: 15 [576/720 (78%)]\tLoss: 14.263505\n",
      "Train Epoch: 15 [640/720 (87%)]\tLoss: 13.837521\n",
      "Train Epoch: 15 [352/720 (96%)]\tLoss: 13.090438\n",
      "====> Epoch: 15 Average loss: 13.3835\n",
      "====> Test set loss: 15.3525\n",
      "Train Epoch: 16 [0/720 (0%)]\tLoss: 11.720374\n",
      "Train Epoch: 16 [64/720 (9%)]\tLoss: 13.556412\n",
      "Train Epoch: 16 [128/720 (17%)]\tLoss: 14.491563\n",
      "Train Epoch: 16 [192/720 (26%)]\tLoss: 12.000577\n",
      "Train Epoch: 16 [256/720 (35%)]\tLoss: 13.346908\n",
      "Train Epoch: 16 [320/720 (43%)]\tLoss: 13.843134\n",
      "Train Epoch: 16 [384/720 (52%)]\tLoss: 12.513461\n",
      "Train Epoch: 16 [448/720 (61%)]\tLoss: 12.993737\n",
      "Train Epoch: 16 [512/720 (70%)]\tLoss: 13.325377\n",
      "Train Epoch: 16 [576/720 (78%)]\tLoss: 11.656444\n",
      "Train Epoch: 16 [640/720 (87%)]\tLoss: 11.822412\n",
      "Train Epoch: 16 [352/720 (96%)]\tLoss: 12.358719\n",
      "====> Epoch: 16 Average loss: 13.2604\n",
      "====> Test set loss: 15.5147\n",
      "Train Epoch: 17 [0/720 (0%)]\tLoss: 12.580937\n",
      "Train Epoch: 17 [64/720 (9%)]\tLoss: 11.175385\n",
      "Train Epoch: 17 [128/720 (17%)]\tLoss: 11.476500\n",
      "Train Epoch: 17 [192/720 (26%)]\tLoss: 14.252471\n",
      "Train Epoch: 17 [256/720 (35%)]\tLoss: 13.596494\n",
      "Train Epoch: 17 [320/720 (43%)]\tLoss: 11.227903\n",
      "Train Epoch: 17 [384/720 (52%)]\tLoss: 13.161367\n",
      "Train Epoch: 17 [448/720 (61%)]\tLoss: 12.504363\n",
      "Train Epoch: 17 [512/720 (70%)]\tLoss: 14.056334\n",
      "Train Epoch: 17 [576/720 (78%)]\tLoss: 13.350120\n",
      "Train Epoch: 17 [640/720 (87%)]\tLoss: 12.688785\n",
      "Train Epoch: 17 [352/720 (96%)]\tLoss: 12.111218\n",
      "====> Epoch: 17 Average loss: 13.1805\n",
      "====> Test set loss: 15.3069\n",
      "Train Epoch: 18 [0/720 (0%)]\tLoss: 11.377280\n",
      "Train Epoch: 18 [64/720 (9%)]\tLoss: 14.029617\n",
      "Train Epoch: 18 [128/720 (17%)]\tLoss: 13.567214\n",
      "Train Epoch: 18 [192/720 (26%)]\tLoss: 13.145514\n",
      "Train Epoch: 18 [256/720 (35%)]\tLoss: 15.058249\n",
      "Train Epoch: 18 [320/720 (43%)]\tLoss: 11.081114\n",
      "Train Epoch: 18 [384/720 (52%)]\tLoss: 13.147975\n",
      "Train Epoch: 18 [448/720 (61%)]\tLoss: 9.895190\n",
      "Train Epoch: 18 [512/720 (70%)]\tLoss: 12.969155\n",
      "Train Epoch: 18 [576/720 (78%)]\tLoss: 14.267557\n",
      "Train Epoch: 18 [640/720 (87%)]\tLoss: 14.576587\n",
      "Train Epoch: 18 [352/720 (96%)]\tLoss: 12.866540\n",
      "====> Epoch: 18 Average loss: 13.1409\n",
      "====> Test set loss: 15.2325\n",
      "Train Epoch: 19 [0/720 (0%)]\tLoss: 14.026750\n",
      "Train Epoch: 19 [64/720 (9%)]\tLoss: 12.731328\n",
      "Train Epoch: 19 [128/720 (17%)]\tLoss: 14.407669\n",
      "Train Epoch: 19 [192/720 (26%)]\tLoss: 12.722115\n",
      "Train Epoch: 19 [256/720 (35%)]\tLoss: 14.421693\n",
      "Train Epoch: 19 [320/720 (43%)]\tLoss: 11.695199\n",
      "Train Epoch: 19 [384/720 (52%)]\tLoss: 13.720940\n",
      "Train Epoch: 19 [448/720 (61%)]\tLoss: 14.144032\n",
      "Train Epoch: 19 [512/720 (70%)]\tLoss: 12.114287\n",
      "Train Epoch: 19 [576/720 (78%)]\tLoss: 14.312277\n",
      "Train Epoch: 19 [640/720 (87%)]\tLoss: 13.172433\n",
      "Train Epoch: 19 [352/720 (96%)]\tLoss: 11.820626\n",
      "====> Epoch: 19 Average loss: 13.0787\n",
      "====> Test set loss: 15.3141\n",
      "Train Epoch: 20 [0/720 (0%)]\tLoss: 12.043856\n",
      "Train Epoch: 20 [64/720 (9%)]\tLoss: 11.706555\n",
      "Train Epoch: 20 [128/720 (17%)]\tLoss: 13.123022\n",
      "Train Epoch: 20 [192/720 (26%)]\tLoss: 15.068024\n",
      "Train Epoch: 20 [256/720 (35%)]\tLoss: 11.823793\n",
      "Train Epoch: 20 [320/720 (43%)]\tLoss: 14.695211\n",
      "Train Epoch: 20 [384/720 (52%)]\tLoss: 14.755217\n",
      "Train Epoch: 20 [448/720 (61%)]\tLoss: 14.047824\n",
      "Train Epoch: 20 [512/720 (70%)]\tLoss: 13.598088\n",
      "Train Epoch: 20 [576/720 (78%)]\tLoss: 10.333065\n",
      "Train Epoch: 20 [640/720 (87%)]\tLoss: 13.550217\n",
      "Train Epoch: 20 [352/720 (96%)]\tLoss: 12.397757\n",
      "====> Epoch: 20 Average loss: 13.0296\n",
      "====> Test set loss: 15.3174\n",
      "Train Epoch: 21 [0/720 (0%)]\tLoss: 13.966206\n",
      "Train Epoch: 21 [64/720 (9%)]\tLoss: 13.027666\n",
      "Train Epoch: 21 [128/720 (17%)]\tLoss: 15.195356\n",
      "Train Epoch: 21 [192/720 (26%)]\tLoss: 12.582998\n",
      "Train Epoch: 21 [256/720 (35%)]\tLoss: 12.885076\n",
      "Train Epoch: 21 [320/720 (43%)]\tLoss: 12.038509\n",
      "Train Epoch: 21 [384/720 (52%)]\tLoss: 11.973985\n",
      "Train Epoch: 21 [448/720 (61%)]\tLoss: 14.546503\n",
      "Train Epoch: 21 [512/720 (70%)]\tLoss: 12.886187\n",
      "Train Epoch: 21 [576/720 (78%)]\tLoss: 10.703062\n",
      "Train Epoch: 21 [640/720 (87%)]\tLoss: 13.547460\n",
      "Train Epoch: 21 [352/720 (96%)]\tLoss: 10.961019\n",
      "====> Epoch: 21 Average loss: 12.9721\n",
      "====> Test set loss: 15.1530\n",
      "Train Epoch: 22 [0/720 (0%)]\tLoss: 13.296963\n",
      "Train Epoch: 22 [64/720 (9%)]\tLoss: 13.727905\n",
      "Train Epoch: 22 [128/720 (17%)]\tLoss: 12.500854\n",
      "Train Epoch: 22 [192/720 (26%)]\tLoss: 13.627427\n",
      "Train Epoch: 22 [256/720 (35%)]\tLoss: 12.585832\n",
      "Train Epoch: 22 [320/720 (43%)]\tLoss: 12.132972\n",
      "Train Epoch: 22 [384/720 (52%)]\tLoss: 14.794766\n",
      "Train Epoch: 22 [448/720 (61%)]\tLoss: 14.838465\n",
      "Train Epoch: 22 [512/720 (70%)]\tLoss: 14.351467\n",
      "Train Epoch: 22 [576/720 (78%)]\tLoss: 11.459896\n",
      "Train Epoch: 22 [640/720 (87%)]\tLoss: 13.996569\n",
      "Train Epoch: 22 [352/720 (96%)]\tLoss: 12.041673\n",
      "====> Epoch: 22 Average loss: 12.9705\n",
      "====> Test set loss: 15.1267\n",
      "Train Epoch: 23 [0/720 (0%)]\tLoss: 13.529431\n",
      "Train Epoch: 23 [64/720 (9%)]\tLoss: 13.031919\n",
      "Train Epoch: 23 [128/720 (17%)]\tLoss: 12.691021\n",
      "Train Epoch: 23 [192/720 (26%)]\tLoss: 11.844772\n",
      "Train Epoch: 23 [256/720 (35%)]\tLoss: 13.508513\n",
      "Train Epoch: 23 [320/720 (43%)]\tLoss: 11.877592\n",
      "Train Epoch: 23 [384/720 (52%)]\tLoss: 12.585829\n",
      "Train Epoch: 23 [448/720 (61%)]\tLoss: 12.980974\n",
      "Train Epoch: 23 [512/720 (70%)]\tLoss: 11.965316\n",
      "Train Epoch: 23 [576/720 (78%)]\tLoss: 14.732130\n",
      "Train Epoch: 23 [640/720 (87%)]\tLoss: 13.960748\n",
      "Train Epoch: 23 [352/720 (96%)]\tLoss: 14.878849\n",
      "====> Epoch: 23 Average loss: 12.9023\n",
      "====> Test set loss: 15.4176\n",
      "Train Epoch: 24 [0/720 (0%)]\tLoss: 12.755599\n",
      "Train Epoch: 24 [64/720 (9%)]\tLoss: 11.802540\n",
      "Train Epoch: 24 [128/720 (17%)]\tLoss: 12.240565\n",
      "Train Epoch: 24 [192/720 (26%)]\tLoss: 13.341201\n",
      "Train Epoch: 24 [256/720 (35%)]\tLoss: 14.075575\n",
      "Train Epoch: 24 [320/720 (43%)]\tLoss: 13.271871\n",
      "Train Epoch: 24 [384/720 (52%)]\tLoss: 12.224065\n",
      "Train Epoch: 24 [448/720 (61%)]\tLoss: 14.973326\n",
      "Train Epoch: 24 [512/720 (70%)]\tLoss: 12.256578\n",
      "Train Epoch: 24 [576/720 (78%)]\tLoss: 13.313418\n",
      "Train Epoch: 24 [640/720 (87%)]\tLoss: 13.514232\n",
      "Train Epoch: 24 [352/720 (96%)]\tLoss: 10.490197\n",
      "====> Epoch: 24 Average loss: 12.9217\n",
      "====> Test set loss: 15.1538\n",
      "Train Epoch: 25 [0/720 (0%)]\tLoss: 11.182260\n",
      "Train Epoch: 25 [64/720 (9%)]\tLoss: 13.417236\n",
      "Train Epoch: 25 [128/720 (17%)]\tLoss: 11.937797\n",
      "Train Epoch: 25 [192/720 (26%)]\tLoss: 11.211875\n",
      "Train Epoch: 25 [256/720 (35%)]\tLoss: 11.113010\n",
      "Train Epoch: 25 [320/720 (43%)]\tLoss: 9.919765\n",
      "Train Epoch: 25 [384/720 (52%)]\tLoss: 11.172951\n",
      "Train Epoch: 25 [448/720 (61%)]\tLoss: 13.418711\n",
      "Train Epoch: 25 [512/720 (70%)]\tLoss: 13.390925\n",
      "Train Epoch: 25 [576/720 (78%)]\tLoss: 12.742178\n",
      "Train Epoch: 25 [640/720 (87%)]\tLoss: 12.451378\n",
      "Train Epoch: 25 [352/720 (96%)]\tLoss: 14.602352\n",
      "====> Epoch: 25 Average loss: 12.8729\n",
      "====> Test set loss: 15.1319\n",
      "Train Epoch: 26 [0/720 (0%)]\tLoss: 13.923016\n",
      "Train Epoch: 26 [64/720 (9%)]\tLoss: 12.280420\n",
      "Train Epoch: 26 [128/720 (17%)]\tLoss: 12.549152\n",
      "Train Epoch: 26 [192/720 (26%)]\tLoss: 12.484737\n",
      "Train Epoch: 26 [256/720 (35%)]\tLoss: 12.841871\n",
      "Train Epoch: 26 [320/720 (43%)]\tLoss: 11.936402\n",
      "Train Epoch: 26 [384/720 (52%)]\tLoss: 10.268009\n",
      "Train Epoch: 26 [448/720 (61%)]\tLoss: 13.902403\n",
      "Train Epoch: 26 [512/720 (70%)]\tLoss: 13.812060\n",
      "Train Epoch: 26 [576/720 (78%)]\tLoss: 11.646082\n",
      "Train Epoch: 26 [640/720 (87%)]\tLoss: 12.237871\n",
      "Train Epoch: 26 [352/720 (96%)]\tLoss: 13.508180\n",
      "====> Epoch: 26 Average loss: 12.7699\n",
      "====> Test set loss: 15.1216\n",
      "Train Epoch: 27 [0/720 (0%)]\tLoss: 12.479060\n",
      "Train Epoch: 27 [64/720 (9%)]\tLoss: 13.635983\n",
      "Train Epoch: 27 [128/720 (17%)]\tLoss: 13.500585\n",
      "Train Epoch: 27 [192/720 (26%)]\tLoss: 11.943235\n",
      "Train Epoch: 27 [256/720 (35%)]\tLoss: 12.483990\n",
      "Train Epoch: 27 [320/720 (43%)]\tLoss: 13.096824\n",
      "Train Epoch: 27 [384/720 (52%)]\tLoss: 11.331653\n",
      "Train Epoch: 27 [448/720 (61%)]\tLoss: 13.224664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [512/720 (70%)]\tLoss: 14.602056\n",
      "Train Epoch: 27 [576/720 (78%)]\tLoss: 13.249741\n",
      "Train Epoch: 27 [640/720 (87%)]\tLoss: 11.125199\n",
      "Train Epoch: 27 [352/720 (96%)]\tLoss: 12.441035\n",
      "====> Epoch: 27 Average loss: 12.7973\n",
      "====> Test set loss: 15.2534\n",
      "Train Epoch: 28 [0/720 (0%)]\tLoss: 12.829718\n",
      "Train Epoch: 28 [64/720 (9%)]\tLoss: 14.099239\n",
      "Train Epoch: 28 [128/720 (17%)]\tLoss: 13.832338\n",
      "Train Epoch: 28 [192/720 (26%)]\tLoss: 15.723982\n",
      "Train Epoch: 28 [256/720 (35%)]\tLoss: 12.216627\n",
      "Train Epoch: 28 [320/720 (43%)]\tLoss: 12.993664\n",
      "Train Epoch: 28 [384/720 (52%)]\tLoss: 13.799588\n",
      "Train Epoch: 28 [448/720 (61%)]\tLoss: 12.187080\n",
      "Train Epoch: 28 [512/720 (70%)]\tLoss: 10.316810\n",
      "Train Epoch: 28 [576/720 (78%)]\tLoss: 12.900422\n",
      "Train Epoch: 28 [640/720 (87%)]\tLoss: 12.756889\n",
      "Train Epoch: 28 [352/720 (96%)]\tLoss: 14.312614\n",
      "====> Epoch: 28 Average loss: 12.7921\n",
      "====> Test set loss: 15.0995\n",
      "Train Epoch: 29 [0/720 (0%)]\tLoss: 12.204105\n",
      "Train Epoch: 29 [64/720 (9%)]\tLoss: 12.799250\n",
      "Train Epoch: 29 [128/720 (17%)]\tLoss: 13.173874\n",
      "Train Epoch: 29 [192/720 (26%)]\tLoss: 12.244216\n",
      "Train Epoch: 29 [256/720 (35%)]\tLoss: 13.389369\n",
      "Train Epoch: 29 [320/720 (43%)]\tLoss: 12.938218\n",
      "Train Epoch: 29 [384/720 (52%)]\tLoss: 13.161186\n",
      "Train Epoch: 29 [448/720 (61%)]\tLoss: 12.380215\n",
      "Train Epoch: 29 [512/720 (70%)]\tLoss: 13.130952\n",
      "Train Epoch: 29 [576/720 (78%)]\tLoss: 13.965383\n",
      "Train Epoch: 29 [640/720 (87%)]\tLoss: 13.039942\n",
      "Train Epoch: 29 [352/720 (96%)]\tLoss: 14.760187\n",
      "====> Epoch: 29 Average loss: 12.7493\n",
      "====> Test set loss: 15.0056\n",
      "Train Epoch: 30 [0/720 (0%)]\tLoss: 10.711837\n",
      "Train Epoch: 30 [64/720 (9%)]\tLoss: 14.764578\n",
      "Train Epoch: 30 [128/720 (17%)]\tLoss: 13.111736\n",
      "Train Epoch: 30 [192/720 (26%)]\tLoss: 12.021709\n",
      "Train Epoch: 30 [256/720 (35%)]\tLoss: 12.558392\n",
      "Train Epoch: 30 [320/720 (43%)]\tLoss: 11.544446\n",
      "Train Epoch: 30 [384/720 (52%)]\tLoss: 13.906619\n",
      "Train Epoch: 30 [448/720 (61%)]\tLoss: 11.722876\n",
      "Train Epoch: 30 [512/720 (70%)]\tLoss: 10.895768\n",
      "Train Epoch: 30 [576/720 (78%)]\tLoss: 13.699526\n",
      "Train Epoch: 30 [640/720 (87%)]\tLoss: 13.062024\n",
      "Train Epoch: 30 [352/720 (96%)]\tLoss: 12.792192\n",
      "====> Epoch: 30 Average loss: 12.6760\n",
      "====> Test set loss: 14.9635\n",
      "Train Epoch: 31 [0/720 (0%)]\tLoss: 13.852531\n",
      "Train Epoch: 31 [64/720 (9%)]\tLoss: 12.904644\n",
      "Train Epoch: 31 [128/720 (17%)]\tLoss: 11.739320\n",
      "Train Epoch: 31 [192/720 (26%)]\tLoss: 11.038635\n",
      "Train Epoch: 31 [256/720 (35%)]\tLoss: 12.008351\n",
      "Train Epoch: 31 [320/720 (43%)]\tLoss: 14.479759\n",
      "Train Epoch: 31 [384/720 (52%)]\tLoss: 11.112940\n",
      "Train Epoch: 31 [448/720 (61%)]\tLoss: 12.108100\n",
      "Train Epoch: 31 [512/720 (70%)]\tLoss: 15.763950\n",
      "Train Epoch: 31 [576/720 (78%)]\tLoss: 13.453372\n",
      "Train Epoch: 31 [640/720 (87%)]\tLoss: 12.283365\n",
      "Train Epoch: 31 [352/720 (96%)]\tLoss: 10.935744\n",
      "====> Epoch: 31 Average loss: 12.7340\n",
      "====> Test set loss: 15.0953\n",
      "Train Epoch: 32 [0/720 (0%)]\tLoss: 13.786388\n",
      "Train Epoch: 32 [64/720 (9%)]\tLoss: 12.546211\n",
      "Train Epoch: 32 [128/720 (17%)]\tLoss: 13.069434\n",
      "Train Epoch: 32 [192/720 (26%)]\tLoss: 13.429066\n",
      "Train Epoch: 32 [256/720 (35%)]\tLoss: 12.386817\n",
      "Train Epoch: 32 [320/720 (43%)]\tLoss: 15.709833\n",
      "Train Epoch: 32 [384/720 (52%)]\tLoss: 11.900515\n",
      "Train Epoch: 32 [448/720 (61%)]\tLoss: 12.515218\n",
      "Train Epoch: 32 [512/720 (70%)]\tLoss: 12.412690\n",
      "Train Epoch: 32 [576/720 (78%)]\tLoss: 13.675787\n",
      "Train Epoch: 32 [640/720 (87%)]\tLoss: 12.560498\n",
      "Train Epoch: 32 [352/720 (96%)]\tLoss: 17.565079\n",
      "====> Epoch: 32 Average loss: 12.7749\n",
      "====> Test set loss: 15.0222\n",
      "Train Epoch: 33 [0/720 (0%)]\tLoss: 11.977540\n",
      "Train Epoch: 33 [64/720 (9%)]\tLoss: 14.026921\n",
      "Train Epoch: 33 [128/720 (17%)]\tLoss: 12.960218\n",
      "Train Epoch: 33 [192/720 (26%)]\tLoss: 11.628539\n",
      "Train Epoch: 33 [256/720 (35%)]\tLoss: 13.682586\n",
      "Train Epoch: 33 [320/720 (43%)]\tLoss: 11.349627\n",
      "Train Epoch: 33 [384/720 (52%)]\tLoss: 11.035230\n",
      "Train Epoch: 33 [448/720 (61%)]\tLoss: 12.194713\n",
      "Train Epoch: 33 [512/720 (70%)]\tLoss: 11.135225\n",
      "Train Epoch: 33 [576/720 (78%)]\tLoss: 13.125698\n",
      "Train Epoch: 33 [640/720 (87%)]\tLoss: 14.237885\n",
      "Train Epoch: 33 [352/720 (96%)]\tLoss: 16.120388\n",
      "====> Epoch: 33 Average loss: 12.6544\n",
      "====> Test set loss: 15.0405\n",
      "Train Epoch: 34 [0/720 (0%)]\tLoss: 12.374890\n",
      "Train Epoch: 34 [64/720 (9%)]\tLoss: 13.200192\n",
      "Train Epoch: 34 [128/720 (17%)]\tLoss: 14.743771\n",
      "Train Epoch: 34 [192/720 (26%)]\tLoss: 12.421845\n",
      "Train Epoch: 34 [256/720 (35%)]\tLoss: 10.753084\n",
      "Train Epoch: 34 [320/720 (43%)]\tLoss: 13.596752\n",
      "Train Epoch: 34 [384/720 (52%)]\tLoss: 13.127284\n",
      "Train Epoch: 34 [448/720 (61%)]\tLoss: 13.704654\n",
      "Train Epoch: 34 [512/720 (70%)]\tLoss: 13.014425\n",
      "Train Epoch: 34 [576/720 (78%)]\tLoss: 10.226566\n",
      "Train Epoch: 34 [640/720 (87%)]\tLoss: 14.824315\n",
      "Train Epoch: 34 [352/720 (96%)]\tLoss: 11.161646\n",
      "====> Epoch: 34 Average loss: 12.6537\n",
      "====> Test set loss: 15.0470\n",
      "Train Epoch: 35 [0/720 (0%)]\tLoss: 11.247311\n",
      "Train Epoch: 35 [64/720 (9%)]\tLoss: 15.775774\n",
      "Train Epoch: 35 [128/720 (17%)]\tLoss: 13.518736\n",
      "Train Epoch: 35 [192/720 (26%)]\tLoss: 13.067295\n",
      "Train Epoch: 35 [256/720 (35%)]\tLoss: 13.027280\n",
      "Train Epoch: 35 [320/720 (43%)]\tLoss: 12.546513\n",
      "Train Epoch: 35 [384/720 (52%)]\tLoss: 15.262300\n",
      "Train Epoch: 35 [448/720 (61%)]\tLoss: 12.084327\n",
      "Train Epoch: 35 [512/720 (70%)]\tLoss: 11.560882\n",
      "Train Epoch: 35 [576/720 (78%)]\tLoss: 11.686995\n",
      "Train Epoch: 35 [640/720 (87%)]\tLoss: 12.919639\n",
      "Train Epoch: 35 [352/720 (96%)]\tLoss: 10.235470\n",
      "====> Epoch: 35 Average loss: 12.6340\n",
      "====> Test set loss: 14.9586\n",
      "Train Epoch: 36 [0/720 (0%)]\tLoss: 12.422553\n",
      "Train Epoch: 36 [64/720 (9%)]\tLoss: 10.332862\n",
      "Train Epoch: 36 [128/720 (17%)]\tLoss: 10.025393\n",
      "Train Epoch: 36 [192/720 (26%)]\tLoss: 12.254884\n",
      "Train Epoch: 36 [256/720 (35%)]\tLoss: 14.875893\n",
      "Train Epoch: 36 [320/720 (43%)]\tLoss: 11.140500\n",
      "Train Epoch: 36 [384/720 (52%)]\tLoss: 9.884438\n",
      "Train Epoch: 36 [448/720 (61%)]\tLoss: 11.982928\n",
      "Train Epoch: 36 [512/720 (70%)]\tLoss: 14.642979\n",
      "Train Epoch: 36 [576/720 (78%)]\tLoss: 12.815186\n",
      "Train Epoch: 36 [640/720 (87%)]\tLoss: 12.230430\n",
      "Train Epoch: 36 [352/720 (96%)]\tLoss: 12.528333\n",
      "====> Epoch: 36 Average loss: 12.6647\n",
      "====> Test set loss: 14.9508\n",
      "Train Epoch: 37 [0/720 (0%)]\tLoss: 14.469116\n",
      "Train Epoch: 37 [64/720 (9%)]\tLoss: 11.058928\n",
      "Train Epoch: 37 [128/720 (17%)]\tLoss: 14.031005\n",
      "Train Epoch: 37 [192/720 (26%)]\tLoss: 11.971397\n",
      "Train Epoch: 37 [256/720 (35%)]\tLoss: 14.231932\n",
      "Train Epoch: 37 [320/720 (43%)]\tLoss: 12.787933\n",
      "Train Epoch: 37 [384/720 (52%)]\tLoss: 12.058338\n",
      "Train Epoch: 37 [448/720 (61%)]\tLoss: 12.142471\n",
      "Train Epoch: 37 [512/720 (70%)]\tLoss: 10.479312\n",
      "Train Epoch: 37 [576/720 (78%)]\tLoss: 14.379683\n",
      "Train Epoch: 37 [640/720 (87%)]\tLoss: 13.880192\n",
      "Train Epoch: 37 [352/720 (96%)]\tLoss: 12.309830\n",
      "====> Epoch: 37 Average loss: 12.5691\n",
      "====> Test set loss: 15.1627\n",
      "Train Epoch: 38 [0/720 (0%)]\tLoss: 12.026516\n",
      "Train Epoch: 38 [64/720 (9%)]\tLoss: 12.937688\n",
      "Train Epoch: 38 [128/720 (17%)]\tLoss: 12.124402\n",
      "Train Epoch: 38 [192/720 (26%)]\tLoss: 10.467798\n",
      "Train Epoch: 38 [256/720 (35%)]\tLoss: 11.662229\n",
      "Train Epoch: 38 [320/720 (43%)]\tLoss: 12.638114\n",
      "Train Epoch: 38 [384/720 (52%)]\tLoss: 13.140502\n",
      "Train Epoch: 38 [448/720 (61%)]\tLoss: 12.666850\n",
      "Train Epoch: 38 [512/720 (70%)]\tLoss: 12.902150\n",
      "Train Epoch: 38 [576/720 (78%)]\tLoss: 10.044650\n",
      "Train Epoch: 38 [640/720 (87%)]\tLoss: 11.228164\n",
      "Train Epoch: 38 [352/720 (96%)]\tLoss: 15.007251\n",
      "====> Epoch: 38 Average loss: 12.5482\n",
      "====> Test set loss: 14.8920\n",
      "Train Epoch: 39 [0/720 (0%)]\tLoss: 13.727018\n",
      "Train Epoch: 39 [64/720 (9%)]\tLoss: 10.743241\n",
      "Train Epoch: 39 [128/720 (17%)]\tLoss: 10.766351\n",
      "Train Epoch: 39 [192/720 (26%)]\tLoss: 13.748601\n",
      "Train Epoch: 39 [256/720 (35%)]\tLoss: 13.496696\n",
      "Train Epoch: 39 [320/720 (43%)]\tLoss: 12.093196\n",
      "Train Epoch: 39 [384/720 (52%)]\tLoss: 14.261563\n",
      "Train Epoch: 39 [448/720 (61%)]\tLoss: 9.695085\n",
      "Train Epoch: 39 [512/720 (70%)]\tLoss: 11.752937\n",
      "Train Epoch: 39 [576/720 (78%)]\tLoss: 13.066962\n",
      "Train Epoch: 39 [640/720 (87%)]\tLoss: 13.012350\n",
      "Train Epoch: 39 [352/720 (96%)]\tLoss: 12.145103\n",
      "====> Epoch: 39 Average loss: 12.4968\n",
      "====> Test set loss: 14.9269\n",
      "Train Epoch: 40 [0/720 (0%)]\tLoss: 11.465641\n",
      "Train Epoch: 40 [64/720 (9%)]\tLoss: 12.569718\n",
      "Train Epoch: 40 [128/720 (17%)]\tLoss: 10.822242\n",
      "Train Epoch: 40 [192/720 (26%)]\tLoss: 12.309608\n",
      "Train Epoch: 40 [256/720 (35%)]\tLoss: 12.665795\n",
      "Train Epoch: 40 [320/720 (43%)]\tLoss: 12.741792\n",
      "Train Epoch: 40 [384/720 (52%)]\tLoss: 16.590664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [448/720 (61%)]\tLoss: 12.141940\n",
      "Train Epoch: 40 [512/720 (70%)]\tLoss: 13.714654\n",
      "Train Epoch: 40 [576/720 (78%)]\tLoss: 12.038718\n",
      "Train Epoch: 40 [640/720 (87%)]\tLoss: 11.700603\n",
      "Train Epoch: 40 [352/720 (96%)]\tLoss: 14.545260\n",
      "====> Epoch: 40 Average loss: 12.4819\n",
      "====> Test set loss: 14.8220\n",
      "Train Epoch: 41 [0/720 (0%)]\tLoss: 12.335330\n",
      "Train Epoch: 41 [64/720 (9%)]\tLoss: 12.206857\n",
      "Train Epoch: 41 [128/720 (17%)]\tLoss: 12.513545\n",
      "Train Epoch: 41 [192/720 (26%)]\tLoss: 11.938486\n",
      "Train Epoch: 41 [256/720 (35%)]\tLoss: 11.161780\n",
      "Train Epoch: 41 [320/720 (43%)]\tLoss: 11.716285\n",
      "Train Epoch: 41 [384/720 (52%)]\tLoss: 12.217349\n",
      "Train Epoch: 41 [448/720 (61%)]\tLoss: 11.654828\n",
      "Train Epoch: 41 [512/720 (70%)]\tLoss: 13.092831\n",
      "Train Epoch: 41 [576/720 (78%)]\tLoss: 14.985875\n",
      "Train Epoch: 41 [640/720 (87%)]\tLoss: 12.829641\n",
      "Train Epoch: 41 [352/720 (96%)]\tLoss: 10.644513\n",
      "====> Epoch: 41 Average loss: 12.4523\n",
      "====> Test set loss: 14.8164\n",
      "Train Epoch: 42 [0/720 (0%)]\tLoss: 11.577024\n",
      "Train Epoch: 42 [64/720 (9%)]\tLoss: 10.396455\n",
      "Train Epoch: 42 [128/720 (17%)]\tLoss: 14.150003\n",
      "Train Epoch: 42 [192/720 (26%)]\tLoss: 12.821636\n",
      "Train Epoch: 42 [256/720 (35%)]\tLoss: 11.819558\n",
      "Train Epoch: 42 [320/720 (43%)]\tLoss: 11.921617\n",
      "Train Epoch: 42 [384/720 (52%)]\tLoss: 13.618092\n",
      "Train Epoch: 42 [448/720 (61%)]\tLoss: 12.000869\n",
      "Train Epoch: 42 [512/720 (70%)]\tLoss: 11.057327\n",
      "Train Epoch: 42 [576/720 (78%)]\tLoss: 11.490660\n",
      "Train Epoch: 42 [640/720 (87%)]\tLoss: 12.779141\n",
      "Train Epoch: 42 [352/720 (96%)]\tLoss: 8.823536\n",
      "====> Epoch: 42 Average loss: 12.4351\n",
      "====> Test set loss: 14.8232\n",
      "Train Epoch: 43 [0/720 (0%)]\tLoss: 14.494811\n",
      "Train Epoch: 43 [64/720 (9%)]\tLoss: 10.662795\n",
      "Train Epoch: 43 [128/720 (17%)]\tLoss: 11.640894\n",
      "Train Epoch: 43 [192/720 (26%)]\tLoss: 10.063085\n",
      "Train Epoch: 43 [256/720 (35%)]\tLoss: 12.394325\n",
      "Train Epoch: 43 [320/720 (43%)]\tLoss: 11.138463\n",
      "Train Epoch: 43 [384/720 (52%)]\tLoss: 11.007884\n",
      "Train Epoch: 43 [448/720 (61%)]\tLoss: 11.658078\n",
      "Train Epoch: 43 [512/720 (70%)]\tLoss: 13.702702\n",
      "Train Epoch: 43 [576/720 (78%)]\tLoss: 12.780435\n",
      "Train Epoch: 43 [640/720 (87%)]\tLoss: 10.904623\n",
      "Train Epoch: 43 [352/720 (96%)]\tLoss: 14.180943\n",
      "====> Epoch: 43 Average loss: 12.4686\n",
      "====> Test set loss: 14.8174\n",
      "Train Epoch: 44 [0/720 (0%)]\tLoss: 12.241936\n",
      "Train Epoch: 44 [64/720 (9%)]\tLoss: 11.377121\n",
      "Train Epoch: 44 [128/720 (17%)]\tLoss: 12.469194\n",
      "Train Epoch: 44 [192/720 (26%)]\tLoss: 13.576995\n",
      "Train Epoch: 44 [256/720 (35%)]\tLoss: 10.972889\n",
      "Train Epoch: 44 [320/720 (43%)]\tLoss: 11.892806\n",
      "Train Epoch: 44 [384/720 (52%)]\tLoss: 11.813491\n",
      "Train Epoch: 44 [448/720 (61%)]\tLoss: 13.271079\n",
      "Train Epoch: 44 [512/720 (70%)]\tLoss: 13.828389\n",
      "Train Epoch: 44 [576/720 (78%)]\tLoss: 11.681529\n",
      "Train Epoch: 44 [640/720 (87%)]\tLoss: 11.752666\n",
      "Train Epoch: 44 [352/720 (96%)]\tLoss: 11.627224\n",
      "====> Epoch: 44 Average loss: 12.4870\n",
      "====> Test set loss: 14.9078\n",
      "Train Epoch: 45 [0/720 (0%)]\tLoss: 12.963122\n",
      "Train Epoch: 45 [64/720 (9%)]\tLoss: 12.653554\n",
      "Train Epoch: 45 [128/720 (17%)]\tLoss: 11.847939\n",
      "Train Epoch: 45 [192/720 (26%)]\tLoss: 13.520354\n",
      "Train Epoch: 45 [256/720 (35%)]\tLoss: 11.366469\n",
      "Train Epoch: 45 [320/720 (43%)]\tLoss: 10.323404\n",
      "Train Epoch: 45 [384/720 (52%)]\tLoss: 15.286785\n",
      "Train Epoch: 45 [448/720 (61%)]\tLoss: 13.211433\n",
      "Train Epoch: 45 [512/720 (70%)]\tLoss: 11.450044\n",
      "Train Epoch: 45 [576/720 (78%)]\tLoss: 10.225403\n",
      "Train Epoch: 45 [640/720 (87%)]\tLoss: 11.296578\n",
      "Train Epoch: 45 [352/720 (96%)]\tLoss: 13.270214\n",
      "====> Epoch: 45 Average loss: 12.4358\n",
      "====> Test set loss: 14.7471\n",
      "Train Epoch: 46 [0/720 (0%)]\tLoss: 13.732346\n",
      "Train Epoch: 46 [64/720 (9%)]\tLoss: 14.520976\n",
      "Train Epoch: 46 [128/720 (17%)]\tLoss: 9.518567\n",
      "Train Epoch: 46 [192/720 (26%)]\tLoss: 14.616499\n",
      "Train Epoch: 46 [256/720 (35%)]\tLoss: 12.428159\n",
      "Train Epoch: 46 [320/720 (43%)]\tLoss: 12.477037\n",
      "Train Epoch: 46 [384/720 (52%)]\tLoss: 13.105101\n",
      "Train Epoch: 46 [448/720 (61%)]\tLoss: 10.823112\n",
      "Train Epoch: 46 [512/720 (70%)]\tLoss: 10.205609\n",
      "Train Epoch: 46 [576/720 (78%)]\tLoss: 10.891723\n",
      "Train Epoch: 46 [640/720 (87%)]\tLoss: 13.532521\n",
      "Train Epoch: 46 [352/720 (96%)]\tLoss: 10.812531\n",
      "====> Epoch: 46 Average loss: 12.3667\n",
      "====> Test set loss: 14.8787\n",
      "Train Epoch: 47 [0/720 (0%)]\tLoss: 14.214928\n",
      "Train Epoch: 47 [64/720 (9%)]\tLoss: 11.436805\n",
      "Train Epoch: 47 [128/720 (17%)]\tLoss: 10.177046\n",
      "Train Epoch: 47 [192/720 (26%)]\tLoss: 10.902457\n",
      "Train Epoch: 47 [256/720 (35%)]\tLoss: 12.430784\n",
      "Train Epoch: 47 [320/720 (43%)]\tLoss: 12.624890\n",
      "Train Epoch: 47 [384/720 (52%)]\tLoss: 11.901385\n",
      "Train Epoch: 47 [448/720 (61%)]\tLoss: 12.613407\n",
      "Train Epoch: 47 [512/720 (70%)]\tLoss: 11.208233\n",
      "Train Epoch: 47 [576/720 (78%)]\tLoss: 12.254833\n",
      "Train Epoch: 47 [640/720 (87%)]\tLoss: 13.045803\n",
      "Train Epoch: 47 [352/720 (96%)]\tLoss: 11.942286\n",
      "====> Epoch: 47 Average loss: 12.4135\n",
      "====> Test set loss: 14.9142\n",
      "Train Epoch: 48 [0/720 (0%)]\tLoss: 14.075336\n",
      "Train Epoch: 48 [64/720 (9%)]\tLoss: 14.591227\n",
      "Train Epoch: 48 [128/720 (17%)]\tLoss: 13.198197\n",
      "Train Epoch: 48 [192/720 (26%)]\tLoss: 13.004740\n",
      "Train Epoch: 48 [256/720 (35%)]\tLoss: 11.188851\n",
      "Train Epoch: 48 [320/720 (43%)]\tLoss: 13.838470\n",
      "Train Epoch: 48 [384/720 (52%)]\tLoss: 14.223457\n",
      "Train Epoch: 48 [448/720 (61%)]\tLoss: 10.576164\n",
      "Train Epoch: 48 [512/720 (70%)]\tLoss: 14.054929\n",
      "Train Epoch: 48 [576/720 (78%)]\tLoss: 11.440806\n",
      "Train Epoch: 48 [640/720 (87%)]\tLoss: 9.722108\n",
      "Train Epoch: 48 [352/720 (96%)]\tLoss: 9.980862\n",
      "====> Epoch: 48 Average loss: 12.3969\n",
      "====> Test set loss: 14.7624\n",
      "Train Epoch: 49 [0/720 (0%)]\tLoss: 13.130605\n",
      "Train Epoch: 49 [64/720 (9%)]\tLoss: 10.190913\n",
      "Train Epoch: 49 [128/720 (17%)]\tLoss: 11.174942\n",
      "Train Epoch: 49 [192/720 (26%)]\tLoss: 12.810854\n",
      "Train Epoch: 49 [256/720 (35%)]\tLoss: 11.576981\n",
      "Train Epoch: 49 [320/720 (43%)]\tLoss: 13.094983\n",
      "Train Epoch: 49 [384/720 (52%)]\tLoss: 13.990940\n",
      "Train Epoch: 49 [448/720 (61%)]\tLoss: 11.328513\n",
      "Train Epoch: 49 [512/720 (70%)]\tLoss: 10.637347\n",
      "Train Epoch: 49 [576/720 (78%)]\tLoss: 12.341544\n",
      "Train Epoch: 49 [640/720 (87%)]\tLoss: 13.418371\n",
      "Train Epoch: 49 [352/720 (96%)]\tLoss: 13.958235\n",
      "====> Epoch: 49 Average loss: 12.3470\n",
      "====> Test set loss: 14.8666\n",
      "Train Epoch: 50 [0/720 (0%)]\tLoss: 11.380051\n",
      "Train Epoch: 50 [64/720 (9%)]\tLoss: 11.422331\n",
      "Train Epoch: 50 [128/720 (17%)]\tLoss: 13.439773\n",
      "Train Epoch: 50 [192/720 (26%)]\tLoss: 12.588842\n",
      "Train Epoch: 50 [256/720 (35%)]\tLoss: 12.198428\n",
      "Train Epoch: 50 [320/720 (43%)]\tLoss: 13.005125\n",
      "Train Epoch: 50 [384/720 (52%)]\tLoss: 13.193472\n",
      "Train Epoch: 50 [448/720 (61%)]\tLoss: 13.144270\n",
      "Train Epoch: 50 [512/720 (70%)]\tLoss: 12.625612\n",
      "Train Epoch: 50 [576/720 (78%)]\tLoss: 11.511035\n",
      "Train Epoch: 50 [640/720 (87%)]\tLoss: 14.431245\n",
      "Train Epoch: 50 [352/720 (96%)]\tLoss: 12.143177\n",
      "====> Epoch: 50 Average loss: 12.4278\n",
      "====> Test set loss: 14.8362\n",
      "Train Epoch: 51 [0/720 (0%)]\tLoss: 12.044668\n",
      "Train Epoch: 51 [64/720 (9%)]\tLoss: 11.242650\n",
      "Train Epoch: 51 [128/720 (17%)]\tLoss: 12.479327\n",
      "Train Epoch: 51 [192/720 (26%)]\tLoss: 11.244179\n",
      "Train Epoch: 51 [256/720 (35%)]\tLoss: 13.370880\n",
      "Train Epoch: 51 [320/720 (43%)]\tLoss: 10.748302\n",
      "Train Epoch: 51 [384/720 (52%)]\tLoss: 10.981588\n",
      "Train Epoch: 51 [448/720 (61%)]\tLoss: 12.909833\n",
      "Train Epoch: 51 [512/720 (70%)]\tLoss: 12.531979\n",
      "Train Epoch: 51 [576/720 (78%)]\tLoss: 11.409614\n",
      "Train Epoch: 51 [640/720 (87%)]\tLoss: 12.542455\n",
      "Train Epoch: 51 [352/720 (96%)]\tLoss: 11.876238\n",
      "====> Epoch: 51 Average loss: 12.4068\n",
      "====> Test set loss: 14.8607\n",
      "Train Epoch: 52 [0/720 (0%)]\tLoss: 8.774990\n",
      "Train Epoch: 52 [64/720 (9%)]\tLoss: 12.280339\n",
      "Train Epoch: 52 [128/720 (17%)]\tLoss: 13.540408\n",
      "Train Epoch: 52 [192/720 (26%)]\tLoss: 14.751369\n",
      "Train Epoch: 52 [256/720 (35%)]\tLoss: 11.655463\n",
      "Train Epoch: 52 [320/720 (43%)]\tLoss: 12.206275\n",
      "Train Epoch: 52 [384/720 (52%)]\tLoss: 11.302572\n",
      "Train Epoch: 52 [448/720 (61%)]\tLoss: 10.664824\n",
      "Train Epoch: 52 [512/720 (70%)]\tLoss: 13.745772\n",
      "Train Epoch: 52 [576/720 (78%)]\tLoss: 12.542577\n",
      "Train Epoch: 52 [640/720 (87%)]\tLoss: 12.382813\n",
      "Train Epoch: 52 [352/720 (96%)]\tLoss: 12.281767\n",
      "====> Epoch: 52 Average loss: 12.3570\n",
      "====> Test set loss: 14.8121\n",
      "Train Epoch: 53 [0/720 (0%)]\tLoss: 12.987031\n",
      "Train Epoch: 53 [64/720 (9%)]\tLoss: 14.484280\n",
      "Train Epoch: 53 [128/720 (17%)]\tLoss: 11.929110\n",
      "Train Epoch: 53 [192/720 (26%)]\tLoss: 10.445961\n",
      "Train Epoch: 53 [256/720 (35%)]\tLoss: 11.718433\n",
      "Train Epoch: 53 [320/720 (43%)]\tLoss: 10.811640\n",
      "Train Epoch: 53 [384/720 (52%)]\tLoss: 12.518373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53 [448/720 (61%)]\tLoss: 13.255745\n",
      "Train Epoch: 53 [512/720 (70%)]\tLoss: 9.944128\n",
      "Train Epoch: 53 [576/720 (78%)]\tLoss: 11.566618\n",
      "Train Epoch: 53 [640/720 (87%)]\tLoss: 11.471787\n",
      "Train Epoch: 53 [352/720 (96%)]\tLoss: 13.386800\n",
      "====> Epoch: 53 Average loss: 12.3853\n",
      "====> Test set loss: 14.9198\n",
      "Train Epoch: 54 [0/720 (0%)]\tLoss: 13.162567\n",
      "Train Epoch: 54 [64/720 (9%)]\tLoss: 12.101654\n",
      "Train Epoch: 54 [128/720 (17%)]\tLoss: 11.398981\n",
      "Train Epoch: 54 [192/720 (26%)]\tLoss: 12.826338\n",
      "Train Epoch: 54 [256/720 (35%)]\tLoss: 14.852366\n",
      "Train Epoch: 54 [320/720 (43%)]\tLoss: 13.885829\n",
      "Train Epoch: 54 [384/720 (52%)]\tLoss: 11.861229\n",
      "Train Epoch: 54 [448/720 (61%)]\tLoss: 12.349731\n",
      "Train Epoch: 54 [512/720 (70%)]\tLoss: 11.690804\n",
      "Train Epoch: 54 [576/720 (78%)]\tLoss: 10.249624\n",
      "Train Epoch: 54 [640/720 (87%)]\tLoss: 12.376845\n",
      "Train Epoch: 54 [352/720 (96%)]\tLoss: 14.952388\n",
      "====> Epoch: 54 Average loss: 12.3818\n",
      "====> Test set loss: 14.9095\n",
      "Train Epoch: 55 [0/720 (0%)]\tLoss: 13.409025\n",
      "Train Epoch: 55 [64/720 (9%)]\tLoss: 10.723389\n",
      "Train Epoch: 55 [128/720 (17%)]\tLoss: 12.618882\n",
      "Train Epoch: 55 [192/720 (26%)]\tLoss: 13.140888\n",
      "Train Epoch: 55 [256/720 (35%)]\tLoss: 12.273297\n",
      "Train Epoch: 55 [320/720 (43%)]\tLoss: 12.111124\n",
      "Train Epoch: 55 [384/720 (52%)]\tLoss: 12.015738\n",
      "Train Epoch: 55 [448/720 (61%)]\tLoss: 11.256784\n",
      "Train Epoch: 55 [512/720 (70%)]\tLoss: 11.419209\n",
      "Train Epoch: 55 [576/720 (78%)]\tLoss: 12.771349\n",
      "Train Epoch: 55 [640/720 (87%)]\tLoss: 11.812028\n",
      "Train Epoch: 55 [352/720 (96%)]\tLoss: 11.969125\n",
      "====> Epoch: 55 Average loss: 12.3084\n",
      "====> Test set loss: 14.8212\n",
      "Train Epoch: 56 [0/720 (0%)]\tLoss: 11.291669\n",
      "Train Epoch: 56 [64/720 (9%)]\tLoss: 12.916653\n",
      "Train Epoch: 56 [128/720 (17%)]\tLoss: 11.174265\n",
      "Train Epoch: 56 [192/720 (26%)]\tLoss: 11.344376\n",
      "Train Epoch: 56 [256/720 (35%)]\tLoss: 13.535328\n",
      "Train Epoch: 56 [320/720 (43%)]\tLoss: 13.158038\n",
      "Train Epoch: 56 [384/720 (52%)]\tLoss: 13.005858\n",
      "Train Epoch: 56 [448/720 (61%)]\tLoss: 12.562948\n",
      "Train Epoch: 56 [512/720 (70%)]\tLoss: 10.531762\n",
      "Train Epoch: 56 [576/720 (78%)]\tLoss: 11.594183\n",
      "Train Epoch: 56 [640/720 (87%)]\tLoss: 11.976821\n",
      "Train Epoch: 56 [352/720 (96%)]\tLoss: 12.266927\n",
      "====> Epoch: 56 Average loss: 12.3246\n",
      "====> Test set loss: 14.8170\n",
      "Train Epoch: 57 [0/720 (0%)]\tLoss: 12.988115\n",
      "Train Epoch: 57 [64/720 (9%)]\tLoss: 12.870714\n",
      "Train Epoch: 57 [128/720 (17%)]\tLoss: 11.892245\n",
      "Train Epoch: 57 [192/720 (26%)]\tLoss: 11.194994\n",
      "Train Epoch: 57 [256/720 (35%)]\tLoss: 13.287849\n",
      "Train Epoch: 57 [320/720 (43%)]\tLoss: 13.526423\n",
      "Train Epoch: 57 [384/720 (52%)]\tLoss: 10.930958\n",
      "Train Epoch: 57 [448/720 (61%)]\tLoss: 11.627914\n",
      "Train Epoch: 57 [512/720 (70%)]\tLoss: 14.281696\n",
      "Train Epoch: 57 [576/720 (78%)]\tLoss: 12.522175\n",
      "Train Epoch: 57 [640/720 (87%)]\tLoss: 13.216944\n",
      "Train Epoch: 57 [352/720 (96%)]\tLoss: 10.898388\n",
      "====> Epoch: 57 Average loss: 12.2791\n",
      "====> Test set loss: 14.7662\n",
      "Train Epoch: 58 [0/720 (0%)]\tLoss: 9.974799\n",
      "Train Epoch: 58 [64/720 (9%)]\tLoss: 12.658507\n",
      "Train Epoch: 58 [128/720 (17%)]\tLoss: 11.877350\n",
      "Train Epoch: 58 [192/720 (26%)]\tLoss: 11.975276\n",
      "Train Epoch: 58 [256/720 (35%)]\tLoss: 12.581766\n",
      "Train Epoch: 58 [320/720 (43%)]\tLoss: 12.943130\n",
      "Train Epoch: 58 [384/720 (52%)]\tLoss: 12.773247\n",
      "Train Epoch: 58 [448/720 (61%)]\tLoss: 13.075090\n",
      "Train Epoch: 58 [512/720 (70%)]\tLoss: 14.203639\n",
      "Train Epoch: 58 [576/720 (78%)]\tLoss: 11.536697\n",
      "Train Epoch: 58 [640/720 (87%)]\tLoss: 13.195908\n",
      "Train Epoch: 58 [352/720 (96%)]\tLoss: 14.296279\n",
      "====> Epoch: 58 Average loss: 12.2969\n",
      "====> Test set loss: 14.8737\n",
      "Train Epoch: 59 [0/720 (0%)]\tLoss: 12.684855\n",
      "Train Epoch: 59 [64/720 (9%)]\tLoss: 13.901683\n",
      "Train Epoch: 59 [128/720 (17%)]\tLoss: 10.008525\n",
      "Train Epoch: 59 [192/720 (26%)]\tLoss: 10.853582\n",
      "Train Epoch: 59 [256/720 (35%)]\tLoss: 14.849375\n",
      "Train Epoch: 59 [320/720 (43%)]\tLoss: 11.437015\n",
      "Train Epoch: 59 [384/720 (52%)]\tLoss: 11.648181\n",
      "Train Epoch: 59 [448/720 (61%)]\tLoss: 12.822416\n",
      "Train Epoch: 59 [512/720 (70%)]\tLoss: 14.367911\n",
      "Train Epoch: 59 [576/720 (78%)]\tLoss: 12.215832\n",
      "Train Epoch: 59 [640/720 (87%)]\tLoss: 11.880069\n",
      "Train Epoch: 59 [352/720 (96%)]\tLoss: 12.906739\n",
      "====> Epoch: 59 Average loss: 12.3176\n",
      "====> Test set loss: 14.7338\n",
      "Train Epoch: 60 [0/720 (0%)]\tLoss: 12.946352\n",
      "Train Epoch: 60 [64/720 (9%)]\tLoss: 9.369246\n",
      "Train Epoch: 60 [128/720 (17%)]\tLoss: 12.790314\n",
      "Train Epoch: 60 [192/720 (26%)]\tLoss: 11.917021\n",
      "Train Epoch: 60 [256/720 (35%)]\tLoss: 12.121853\n",
      "Train Epoch: 60 [320/720 (43%)]\tLoss: 15.323814\n",
      "Train Epoch: 60 [384/720 (52%)]\tLoss: 12.661393\n",
      "Train Epoch: 60 [448/720 (61%)]\tLoss: 13.321627\n",
      "Train Epoch: 60 [512/720 (70%)]\tLoss: 13.205292\n",
      "Train Epoch: 60 [576/720 (78%)]\tLoss: 12.936752\n",
      "Train Epoch: 60 [640/720 (87%)]\tLoss: 12.308089\n",
      "Train Epoch: 60 [352/720 (96%)]\tLoss: 10.721225\n",
      "====> Epoch: 60 Average loss: 12.2492\n",
      "====> Test set loss: 14.7664\n",
      "Train Epoch: 61 [0/720 (0%)]\tLoss: 13.683632\n",
      "Train Epoch: 61 [64/720 (9%)]\tLoss: 14.045134\n",
      "Train Epoch: 61 [128/720 (17%)]\tLoss: 13.591434\n",
      "Train Epoch: 61 [192/720 (26%)]\tLoss: 12.881416\n",
      "Train Epoch: 61 [256/720 (35%)]\tLoss: 13.327112\n",
      "Train Epoch: 61 [320/720 (43%)]\tLoss: 13.525048\n",
      "Train Epoch: 61 [384/720 (52%)]\tLoss: 11.714630\n",
      "Train Epoch: 61 [448/720 (61%)]\tLoss: 10.762504\n",
      "Train Epoch: 61 [512/720 (70%)]\tLoss: 10.407692\n",
      "Train Epoch: 61 [576/720 (78%)]\tLoss: 10.612649\n",
      "Train Epoch: 61 [640/720 (87%)]\tLoss: 11.147409\n",
      "Train Epoch: 61 [352/720 (96%)]\tLoss: 9.650048\n",
      "====> Epoch: 61 Average loss: 12.2617\n",
      "====> Test set loss: 14.6775\n",
      "Train Epoch: 62 [0/720 (0%)]\tLoss: 11.720163\n",
      "Train Epoch: 62 [64/720 (9%)]\tLoss: 11.070421\n",
      "Train Epoch: 62 [128/720 (17%)]\tLoss: 10.045072\n",
      "Train Epoch: 62 [192/720 (26%)]\tLoss: 13.128314\n",
      "Train Epoch: 62 [256/720 (35%)]\tLoss: 13.882557\n",
      "Train Epoch: 62 [320/720 (43%)]\tLoss: 12.346547\n",
      "Train Epoch: 62 [384/720 (52%)]\tLoss: 10.778014\n",
      "Train Epoch: 62 [448/720 (61%)]\tLoss: 11.469320\n",
      "Train Epoch: 62 [512/720 (70%)]\tLoss: 12.388863\n",
      "Train Epoch: 62 [576/720 (78%)]\tLoss: 12.431213\n",
      "Train Epoch: 62 [640/720 (87%)]\tLoss: 12.538138\n",
      "Train Epoch: 62 [352/720 (96%)]\tLoss: 11.875393\n",
      "====> Epoch: 62 Average loss: 12.2162\n",
      "====> Test set loss: 14.8077\n",
      "Train Epoch: 63 [0/720 (0%)]\tLoss: 10.682453\n",
      "Train Epoch: 63 [64/720 (9%)]\tLoss: 11.561078\n",
      "Train Epoch: 63 [128/720 (17%)]\tLoss: 10.813028\n",
      "Train Epoch: 63 [192/720 (26%)]\tLoss: 13.533422\n",
      "Train Epoch: 63 [256/720 (35%)]\tLoss: 12.138348\n",
      "Train Epoch: 63 [320/720 (43%)]\tLoss: 12.128084\n",
      "Train Epoch: 63 [384/720 (52%)]\tLoss: 11.967161\n",
      "Train Epoch: 63 [448/720 (61%)]\tLoss: 12.553795\n",
      "Train Epoch: 63 [512/720 (70%)]\tLoss: 13.778446\n",
      "Train Epoch: 63 [576/720 (78%)]\tLoss: 13.676827\n",
      "Train Epoch: 63 [640/720 (87%)]\tLoss: 11.678729\n",
      "Train Epoch: 63 [352/720 (96%)]\tLoss: 14.260948\n",
      "====> Epoch: 63 Average loss: 12.3030\n",
      "====> Test set loss: 14.8026\n",
      "Train Epoch: 64 [0/720 (0%)]\tLoss: 13.383380\n",
      "Train Epoch: 64 [64/720 (9%)]\tLoss: 9.855381\n",
      "Train Epoch: 64 [128/720 (17%)]\tLoss: 12.269135\n",
      "Train Epoch: 64 [192/720 (26%)]\tLoss: 12.623020\n",
      "Train Epoch: 64 [256/720 (35%)]\tLoss: 11.797160\n",
      "Train Epoch: 64 [320/720 (43%)]\tLoss: 10.294204\n",
      "Train Epoch: 64 [384/720 (52%)]\tLoss: 11.331034\n",
      "Train Epoch: 64 [448/720 (61%)]\tLoss: 11.809002\n",
      "Train Epoch: 64 [512/720 (70%)]\tLoss: 12.387234\n",
      "Train Epoch: 64 [576/720 (78%)]\tLoss: 13.576645\n",
      "Train Epoch: 64 [640/720 (87%)]\tLoss: 11.938475\n",
      "Train Epoch: 64 [352/720 (96%)]\tLoss: 13.119480\n",
      "====> Epoch: 64 Average loss: 12.2931\n",
      "====> Test set loss: 14.7991\n",
      "Train Epoch: 65 [0/720 (0%)]\tLoss: 11.574093\n",
      "Train Epoch: 65 [64/720 (9%)]\tLoss: 12.556952\n",
      "Train Epoch: 65 [128/720 (17%)]\tLoss: 9.746221\n",
      "Train Epoch: 65 [192/720 (26%)]\tLoss: 11.619514\n",
      "Train Epoch: 65 [256/720 (35%)]\tLoss: 13.089861\n",
      "Train Epoch: 65 [320/720 (43%)]\tLoss: 14.260908\n",
      "Train Epoch: 65 [384/720 (52%)]\tLoss: 10.433976\n",
      "Train Epoch: 65 [448/720 (61%)]\tLoss: 10.399344\n",
      "Train Epoch: 65 [512/720 (70%)]\tLoss: 15.100272\n",
      "Train Epoch: 65 [576/720 (78%)]\tLoss: 13.789340\n",
      "Train Epoch: 65 [640/720 (87%)]\tLoss: 12.780231\n",
      "Train Epoch: 65 [352/720 (96%)]\tLoss: 9.678049\n",
      "====> Epoch: 65 Average loss: 12.2327\n",
      "====> Test set loss: 14.7392\n",
      "Train Epoch: 66 [0/720 (0%)]\tLoss: 12.143543\n",
      "Train Epoch: 66 [64/720 (9%)]\tLoss: 13.632607\n",
      "Train Epoch: 66 [128/720 (17%)]\tLoss: 11.481089\n",
      "Train Epoch: 66 [192/720 (26%)]\tLoss: 14.056571\n",
      "Train Epoch: 66 [256/720 (35%)]\tLoss: 11.694782\n",
      "Train Epoch: 66 [320/720 (43%)]\tLoss: 11.287646\n",
      "Train Epoch: 66 [384/720 (52%)]\tLoss: 12.823567\n",
      "Train Epoch: 66 [448/720 (61%)]\tLoss: 11.226832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 66 [512/720 (70%)]\tLoss: 13.754736\n",
      "Train Epoch: 66 [576/720 (78%)]\tLoss: 13.653694\n",
      "Train Epoch: 66 [640/720 (87%)]\tLoss: 11.814105\n",
      "Train Epoch: 66 [352/720 (96%)]\tLoss: 11.319656\n",
      "====> Epoch: 66 Average loss: 12.2126\n",
      "====> Test set loss: 14.6609\n",
      "Train Epoch: 67 [0/720 (0%)]\tLoss: 14.289850\n",
      "Train Epoch: 67 [64/720 (9%)]\tLoss: 14.299154\n",
      "Train Epoch: 67 [128/720 (17%)]\tLoss: 10.912335\n",
      "Train Epoch: 67 [192/720 (26%)]\tLoss: 10.067993\n",
      "Train Epoch: 67 [256/720 (35%)]\tLoss: 11.955750\n",
      "Train Epoch: 67 [320/720 (43%)]\tLoss: 13.194828\n",
      "Train Epoch: 67 [384/720 (52%)]\tLoss: 12.627112\n",
      "Train Epoch: 67 [448/720 (61%)]\tLoss: 13.352651\n",
      "Train Epoch: 67 [512/720 (70%)]\tLoss: 11.629585\n",
      "Train Epoch: 67 [576/720 (78%)]\tLoss: 11.163652\n",
      "Train Epoch: 67 [640/720 (87%)]\tLoss: 11.605281\n",
      "Train Epoch: 67 [352/720 (96%)]\tLoss: 10.386312\n",
      "====> Epoch: 67 Average loss: 12.1619\n",
      "====> Test set loss: 14.7165\n",
      "Train Epoch: 68 [0/720 (0%)]\tLoss: 11.863786\n",
      "Train Epoch: 68 [64/720 (9%)]\tLoss: 11.452944\n",
      "Train Epoch: 68 [128/720 (17%)]\tLoss: 11.725090\n",
      "Train Epoch: 68 [192/720 (26%)]\tLoss: 11.540885\n",
      "Train Epoch: 68 [256/720 (35%)]\tLoss: 9.807235\n",
      "Train Epoch: 68 [320/720 (43%)]\tLoss: 14.169360\n",
      "Train Epoch: 68 [384/720 (52%)]\tLoss: 10.400197\n",
      "Train Epoch: 68 [448/720 (61%)]\tLoss: 12.933248\n",
      "Train Epoch: 68 [512/720 (70%)]\tLoss: 12.633802\n",
      "Train Epoch: 68 [576/720 (78%)]\tLoss: 10.032520\n",
      "Train Epoch: 68 [640/720 (87%)]\tLoss: 11.776748\n",
      "Train Epoch: 68 [352/720 (96%)]\tLoss: 10.638804\n",
      "====> Epoch: 68 Average loss: 12.1632\n",
      "====> Test set loss: 14.7660\n",
      "Train Epoch: 69 [0/720 (0%)]\tLoss: 9.658091\n",
      "Train Epoch: 69 [64/720 (9%)]\tLoss: 12.399006\n",
      "Train Epoch: 69 [128/720 (17%)]\tLoss: 11.518768\n",
      "Train Epoch: 69 [192/720 (26%)]\tLoss: 11.774258\n",
      "Train Epoch: 69 [256/720 (35%)]\tLoss: 11.117243\n",
      "Train Epoch: 69 [320/720 (43%)]\tLoss: 12.717650\n",
      "Train Epoch: 69 [384/720 (52%)]\tLoss: 10.744008\n",
      "Train Epoch: 69 [448/720 (61%)]\tLoss: 11.465702\n",
      "Train Epoch: 69 [512/720 (70%)]\tLoss: 12.550056\n",
      "Train Epoch: 69 [576/720 (78%)]\tLoss: 13.658780\n",
      "Train Epoch: 69 [640/720 (87%)]\tLoss: 14.526279\n",
      "Train Epoch: 69 [352/720 (96%)]\tLoss: 14.090752\n",
      "====> Epoch: 69 Average loss: 12.1562\n",
      "====> Test set loss: 14.8013\n",
      "Train Epoch: 70 [0/720 (0%)]\tLoss: 15.089887\n",
      "Train Epoch: 70 [64/720 (9%)]\tLoss: 10.536007\n",
      "Train Epoch: 70 [128/720 (17%)]\tLoss: 12.614915\n",
      "Train Epoch: 70 [192/720 (26%)]\tLoss: 13.459657\n",
      "Train Epoch: 70 [256/720 (35%)]\tLoss: 13.910506\n",
      "Train Epoch: 70 [320/720 (43%)]\tLoss: 12.287235\n",
      "Train Epoch: 70 [384/720 (52%)]\tLoss: 11.375498\n",
      "Train Epoch: 70 [448/720 (61%)]\tLoss: 10.903484\n",
      "Train Epoch: 70 [512/720 (70%)]\tLoss: 12.484730\n",
      "Train Epoch: 70 [576/720 (78%)]\tLoss: 11.610112\n",
      "Train Epoch: 70 [640/720 (87%)]\tLoss: 11.224803\n",
      "Train Epoch: 70 [352/720 (96%)]\tLoss: 11.513622\n",
      "====> Epoch: 70 Average loss: 12.2101\n",
      "====> Test set loss: 14.9263\n",
      "Train Epoch: 71 [0/720 (0%)]\tLoss: 13.367145\n",
      "Train Epoch: 71 [64/720 (9%)]\tLoss: 12.319328\n",
      "Train Epoch: 71 [128/720 (17%)]\tLoss: 10.814598\n",
      "Train Epoch: 71 [192/720 (26%)]\tLoss: 14.654514\n",
      "Train Epoch: 71 [256/720 (35%)]\tLoss: 11.325258\n",
      "Train Epoch: 71 [320/720 (43%)]\tLoss: 13.675199\n",
      "Train Epoch: 71 [384/720 (52%)]\tLoss: 12.620205\n",
      "Train Epoch: 71 [448/720 (61%)]\tLoss: 11.388710\n",
      "Train Epoch: 71 [512/720 (70%)]\tLoss: 10.405827\n",
      "Train Epoch: 71 [576/720 (78%)]\tLoss: 13.587618\n",
      "Train Epoch: 71 [640/720 (87%)]\tLoss: 14.191763\n",
      "Train Epoch: 71 [352/720 (96%)]\tLoss: 11.519536\n",
      "====> Epoch: 71 Average loss: 12.2718\n",
      "====> Test set loss: 14.8833\n",
      "Train Epoch: 72 [0/720 (0%)]\tLoss: 11.496888\n",
      "Train Epoch: 72 [64/720 (9%)]\tLoss: 11.169994\n",
      "Train Epoch: 72 [128/720 (17%)]\tLoss: 14.505837\n",
      "Train Epoch: 72 [192/720 (26%)]\tLoss: 11.222087\n",
      "Train Epoch: 72 [256/720 (35%)]\tLoss: 11.911638\n",
      "Train Epoch: 72 [320/720 (43%)]\tLoss: 11.061387\n",
      "Train Epoch: 72 [384/720 (52%)]\tLoss: 10.341863\n",
      "Train Epoch: 72 [448/720 (61%)]\tLoss: 12.578696\n",
      "Train Epoch: 72 [512/720 (70%)]\tLoss: 13.042964\n",
      "Train Epoch: 72 [576/720 (78%)]\tLoss: 11.738816\n",
      "Train Epoch: 72 [640/720 (87%)]\tLoss: 13.047138\n",
      "Train Epoch: 72 [352/720 (96%)]\tLoss: 13.682886\n",
      "====> Epoch: 72 Average loss: 12.2662\n",
      "====> Test set loss: 14.7363\n",
      "Train Epoch: 73 [0/720 (0%)]\tLoss: 12.230735\n",
      "Train Epoch: 73 [64/720 (9%)]\tLoss: 11.701751\n",
      "Train Epoch: 73 [128/720 (17%)]\tLoss: 12.825855\n",
      "Train Epoch: 73 [192/720 (26%)]\tLoss: 14.859669\n",
      "Train Epoch: 73 [256/720 (35%)]\tLoss: 13.283758\n",
      "Train Epoch: 73 [320/720 (43%)]\tLoss: 11.320418\n",
      "Train Epoch: 73 [384/720 (52%)]\tLoss: 12.723551\n",
      "Train Epoch: 73 [448/720 (61%)]\tLoss: 12.082794\n",
      "Train Epoch: 73 [512/720 (70%)]\tLoss: 11.532216\n",
      "Train Epoch: 73 [576/720 (78%)]\tLoss: 11.352982\n",
      "Train Epoch: 73 [640/720 (87%)]\tLoss: 10.918576\n",
      "Train Epoch: 73 [352/720 (96%)]\tLoss: 13.039597\n",
      "====> Epoch: 73 Average loss: 12.1873\n",
      "====> Test set loss: 14.7119\n",
      "Train Epoch: 74 [0/720 (0%)]\tLoss: 12.064692\n",
      "Train Epoch: 74 [64/720 (9%)]\tLoss: 12.437507\n",
      "Train Epoch: 74 [128/720 (17%)]\tLoss: 10.691308\n",
      "Train Epoch: 74 [192/720 (26%)]\tLoss: 12.788527\n",
      "Train Epoch: 74 [256/720 (35%)]\tLoss: 13.933954\n",
      "Train Epoch: 74 [320/720 (43%)]\tLoss: 10.235177\n",
      "Train Epoch: 74 [384/720 (52%)]\tLoss: 11.355551\n",
      "Train Epoch: 74 [448/720 (61%)]\tLoss: 12.984394\n",
      "Train Epoch: 74 [512/720 (70%)]\tLoss: 10.121116\n",
      "Train Epoch: 74 [576/720 (78%)]\tLoss: 10.971539\n",
      "Train Epoch: 74 [640/720 (87%)]\tLoss: 14.546812\n",
      "Train Epoch: 74 [352/720 (96%)]\tLoss: 13.864154\n",
      "====> Epoch: 74 Average loss: 12.1422\n",
      "====> Test set loss: 14.7767\n",
      "Train Epoch: 75 [0/720 (0%)]\tLoss: 12.865561\n",
      "Train Epoch: 75 [64/720 (9%)]\tLoss: 12.191773\n",
      "Train Epoch: 75 [128/720 (17%)]\tLoss: 12.035437\n",
      "Train Epoch: 75 [192/720 (26%)]\tLoss: 12.067987\n",
      "Train Epoch: 75 [256/720 (35%)]\tLoss: 11.509535\n",
      "Train Epoch: 75 [320/720 (43%)]\tLoss: 12.853594\n",
      "Train Epoch: 75 [384/720 (52%)]\tLoss: 10.180641\n",
      "Train Epoch: 75 [448/720 (61%)]\tLoss: 10.018082\n",
      "Train Epoch: 75 [512/720 (70%)]\tLoss: 12.163220\n",
      "Train Epoch: 75 [576/720 (78%)]\tLoss: 11.006598\n",
      "Train Epoch: 75 [640/720 (87%)]\tLoss: 12.038307\n",
      "Train Epoch: 75 [352/720 (96%)]\tLoss: 7.960484\n",
      "====> Epoch: 75 Average loss: 12.1839\n",
      "====> Test set loss: 14.6742\n",
      "Train Epoch: 76 [0/720 (0%)]\tLoss: 13.938335\n",
      "Train Epoch: 76 [64/720 (9%)]\tLoss: 12.912225\n",
      "Train Epoch: 76 [128/720 (17%)]\tLoss: 11.005947\n",
      "Train Epoch: 76 [192/720 (26%)]\tLoss: 10.950118\n",
      "Train Epoch: 76 [256/720 (35%)]\tLoss: 12.082002\n",
      "Train Epoch: 76 [320/720 (43%)]\tLoss: 11.921865\n",
      "Train Epoch: 76 [384/720 (52%)]\tLoss: 11.235193\n",
      "Train Epoch: 76 [448/720 (61%)]\tLoss: 12.265990\n",
      "Train Epoch: 76 [512/720 (70%)]\tLoss: 12.477640\n",
      "Train Epoch: 76 [576/720 (78%)]\tLoss: 10.489717\n",
      "Train Epoch: 76 [640/720 (87%)]\tLoss: 14.697611\n",
      "Train Epoch: 76 [352/720 (96%)]\tLoss: 15.390689\n",
      "====> Epoch: 76 Average loss: 12.1253\n",
      "====> Test set loss: 14.8557\n",
      "Train Epoch: 77 [0/720 (0%)]\tLoss: 12.078167\n",
      "Train Epoch: 77 [64/720 (9%)]\tLoss: 10.037375\n",
      "Train Epoch: 77 [128/720 (17%)]\tLoss: 14.926390\n",
      "Train Epoch: 77 [192/720 (26%)]\tLoss: 12.800139\n",
      "Train Epoch: 77 [256/720 (35%)]\tLoss: 13.040535\n",
      "Train Epoch: 77 [320/720 (43%)]\tLoss: 12.770801\n",
      "Train Epoch: 77 [384/720 (52%)]\tLoss: 14.031476\n",
      "Train Epoch: 77 [448/720 (61%)]\tLoss: 13.993032\n",
      "Train Epoch: 77 [512/720 (70%)]\tLoss: 13.319926\n",
      "Train Epoch: 77 [576/720 (78%)]\tLoss: 13.046057\n",
      "Train Epoch: 77 [640/720 (87%)]\tLoss: 11.196924\n",
      "Train Epoch: 77 [352/720 (96%)]\tLoss: 10.885835\n",
      "====> Epoch: 77 Average loss: 12.2713\n",
      "====> Test set loss: 14.9243\n",
      "Train Epoch: 78 [0/720 (0%)]\tLoss: 16.007219\n",
      "Train Epoch: 78 [64/720 (9%)]\tLoss: 11.434270\n",
      "Train Epoch: 78 [128/720 (17%)]\tLoss: 13.072337\n",
      "Train Epoch: 78 [192/720 (26%)]\tLoss: 10.069134\n",
      "Train Epoch: 78 [256/720 (35%)]\tLoss: 12.932186\n",
      "Train Epoch: 78 [320/720 (43%)]\tLoss: 10.873388\n",
      "Train Epoch: 78 [384/720 (52%)]\tLoss: 11.828056\n",
      "Train Epoch: 78 [448/720 (61%)]\tLoss: 12.786820\n",
      "Train Epoch: 78 [512/720 (70%)]\tLoss: 12.914869\n",
      "Train Epoch: 78 [576/720 (78%)]\tLoss: 12.700138\n",
      "Train Epoch: 78 [640/720 (87%)]\tLoss: 13.586867\n",
      "Train Epoch: 78 [352/720 (96%)]\tLoss: 11.564670\n",
      "====> Epoch: 78 Average loss: 12.1969\n",
      "====> Test set loss: 14.7684\n",
      "Train Epoch: 79 [0/720 (0%)]\tLoss: 11.155514\n",
      "Train Epoch: 79 [64/720 (9%)]\tLoss: 11.956748\n",
      "Train Epoch: 79 [128/720 (17%)]\tLoss: 14.289273\n",
      "Train Epoch: 79 [192/720 (26%)]\tLoss: 10.683067\n",
      "Train Epoch: 79 [256/720 (35%)]\tLoss: 10.529858\n",
      "Train Epoch: 79 [320/720 (43%)]\tLoss: 13.020442\n",
      "Train Epoch: 79 [384/720 (52%)]\tLoss: 13.796000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 79 [448/720 (61%)]\tLoss: 11.359894\n",
      "Train Epoch: 79 [512/720 (70%)]\tLoss: 11.561625\n",
      "Train Epoch: 79 [576/720 (78%)]\tLoss: 11.171926\n",
      "Train Epoch: 79 [640/720 (87%)]\tLoss: 10.653967\n",
      "Train Epoch: 79 [352/720 (96%)]\tLoss: 10.876012\n",
      "====> Epoch: 79 Average loss: 12.1315\n",
      "====> Test set loss: 14.6998\n",
      "Train Epoch: 80 [0/720 (0%)]\tLoss: 10.618443\n",
      "Train Epoch: 80 [64/720 (9%)]\tLoss: 10.502734\n",
      "Train Epoch: 80 [128/720 (17%)]\tLoss: 11.290457\n",
      "Train Epoch: 80 [192/720 (26%)]\tLoss: 10.217993\n",
      "Train Epoch: 80 [256/720 (35%)]\tLoss: 12.794280\n",
      "Train Epoch: 80 [320/720 (43%)]\tLoss: 12.845371\n",
      "Train Epoch: 80 [384/720 (52%)]\tLoss: 12.887066\n",
      "Train Epoch: 80 [448/720 (61%)]\tLoss: 12.204148\n",
      "Train Epoch: 80 [512/720 (70%)]\tLoss: 10.039836\n",
      "Train Epoch: 80 [576/720 (78%)]\tLoss: 12.800296\n",
      "Train Epoch: 80 [640/720 (87%)]\tLoss: 12.540554\n",
      "Train Epoch: 80 [352/720 (96%)]\tLoss: 10.794088\n",
      "====> Epoch: 80 Average loss: 12.0989\n",
      "====> Test set loss: 14.6510\n",
      "Train Epoch: 81 [0/720 (0%)]\tLoss: 12.538062\n",
      "Train Epoch: 81 [64/720 (9%)]\tLoss: 12.291952\n",
      "Train Epoch: 81 [128/720 (17%)]\tLoss: 12.992499\n",
      "Train Epoch: 81 [192/720 (26%)]\tLoss: 11.712976\n",
      "Train Epoch: 81 [256/720 (35%)]\tLoss: 10.567763\n",
      "Train Epoch: 81 [320/720 (43%)]\tLoss: 12.744512\n",
      "Train Epoch: 81 [384/720 (52%)]\tLoss: 11.363245\n",
      "Train Epoch: 81 [448/720 (61%)]\tLoss: 11.107093\n",
      "Train Epoch: 81 [512/720 (70%)]\tLoss: 14.221661\n",
      "Train Epoch: 81 [576/720 (78%)]\tLoss: 10.417584\n",
      "Train Epoch: 81 [640/720 (87%)]\tLoss: 13.549025\n",
      "Train Epoch: 81 [352/720 (96%)]\tLoss: 11.653237\n",
      "====> Epoch: 81 Average loss: 12.0699\n",
      "====> Test set loss: 15.0573\n",
      "Train Epoch: 82 [0/720 (0%)]\tLoss: 11.851377\n",
      "Train Epoch: 82 [64/720 (9%)]\tLoss: 12.185676\n",
      "Train Epoch: 82 [128/720 (17%)]\tLoss: 11.159328\n",
      "Train Epoch: 82 [192/720 (26%)]\tLoss: 13.302015\n",
      "Train Epoch: 82 [256/720 (35%)]\tLoss: 11.419968\n",
      "Train Epoch: 82 [320/720 (43%)]\tLoss: 13.099360\n",
      "Train Epoch: 82 [384/720 (52%)]\tLoss: 13.484120\n",
      "Train Epoch: 82 [448/720 (61%)]\tLoss: 11.985305\n",
      "Train Epoch: 82 [512/720 (70%)]\tLoss: 11.307095\n",
      "Train Epoch: 82 [576/720 (78%)]\tLoss: 9.642673\n",
      "Train Epoch: 82 [640/720 (87%)]\tLoss: 12.491304\n",
      "Train Epoch: 82 [352/720 (96%)]\tLoss: 13.958143\n",
      "====> Epoch: 82 Average loss: 12.2677\n",
      "====> Test set loss: 14.8240\n",
      "Train Epoch: 83 [0/720 (0%)]\tLoss: 13.086381\n",
      "Train Epoch: 83 [64/720 (9%)]\tLoss: 12.186961\n",
      "Train Epoch: 83 [128/720 (17%)]\tLoss: 11.982906\n",
      "Train Epoch: 83 [192/720 (26%)]\tLoss: 12.762020\n",
      "Train Epoch: 83 [256/720 (35%)]\tLoss: 11.975232\n",
      "Train Epoch: 83 [320/720 (43%)]\tLoss: 11.534579\n",
      "Train Epoch: 83 [384/720 (52%)]\tLoss: 11.105165\n",
      "Train Epoch: 83 [448/720 (61%)]\tLoss: 12.470036\n",
      "Train Epoch: 83 [512/720 (70%)]\tLoss: 10.667436\n",
      "Train Epoch: 83 [576/720 (78%)]\tLoss: 13.033321\n",
      "Train Epoch: 83 [640/720 (87%)]\tLoss: 13.090046\n",
      "Train Epoch: 83 [352/720 (96%)]\tLoss: 13.186018\n",
      "====> Epoch: 83 Average loss: 12.1483\n",
      "====> Test set loss: 14.7071\n",
      "Train Epoch: 84 [0/720 (0%)]\tLoss: 12.344503\n",
      "Train Epoch: 84 [64/720 (9%)]\tLoss: 10.720204\n",
      "Train Epoch: 84 [128/720 (17%)]\tLoss: 11.405479\n",
      "Train Epoch: 84 [192/720 (26%)]\tLoss: 11.687761\n",
      "Train Epoch: 84 [256/720 (35%)]\tLoss: 13.112205\n",
      "Train Epoch: 84 [320/720 (43%)]\tLoss: 12.710529\n",
      "Train Epoch: 84 [384/720 (52%)]\tLoss: 11.355380\n",
      "Train Epoch: 84 [448/720 (61%)]\tLoss: 14.164658\n",
      "Train Epoch: 84 [512/720 (70%)]\tLoss: 12.990348\n",
      "Train Epoch: 84 [576/720 (78%)]\tLoss: 15.391962\n",
      "Train Epoch: 84 [640/720 (87%)]\tLoss: 11.237987\n",
      "Train Epoch: 84 [352/720 (96%)]\tLoss: 13.163552\n",
      "====> Epoch: 84 Average loss: 12.1306\n",
      "====> Test set loss: 14.9564\n",
      "Train Epoch: 85 [0/720 (0%)]\tLoss: 13.482327\n",
      "Train Epoch: 85 [64/720 (9%)]\tLoss: 12.051299\n",
      "Train Epoch: 85 [128/720 (17%)]\tLoss: 12.327257\n",
      "Train Epoch: 85 [192/720 (26%)]\tLoss: 13.057463\n",
      "Train Epoch: 85 [256/720 (35%)]\tLoss: 11.577804\n",
      "Train Epoch: 85 [320/720 (43%)]\tLoss: 11.215982\n",
      "Train Epoch: 85 [384/720 (52%)]\tLoss: 10.891786\n",
      "Train Epoch: 85 [448/720 (61%)]\tLoss: 11.701675\n",
      "Train Epoch: 85 [512/720 (70%)]\tLoss: 12.072981\n",
      "Train Epoch: 85 [576/720 (78%)]\tLoss: 10.845746\n",
      "Train Epoch: 85 [640/720 (87%)]\tLoss: 11.466726\n",
      "Train Epoch: 85 [352/720 (96%)]\tLoss: 10.242086\n",
      "====> Epoch: 85 Average loss: 12.2630\n",
      "====> Test set loss: 14.6736\n",
      "Train Epoch: 86 [0/720 (0%)]\tLoss: 11.599881\n",
      "Train Epoch: 86 [64/720 (9%)]\tLoss: 11.994791\n",
      "Train Epoch: 86 [128/720 (17%)]\tLoss: 11.031261\n",
      "Train Epoch: 86 [192/720 (26%)]\tLoss: 11.653072\n",
      "Train Epoch: 86 [256/720 (35%)]\tLoss: 13.244584\n",
      "Train Epoch: 86 [320/720 (43%)]\tLoss: 10.830329\n",
      "Train Epoch: 86 [384/720 (52%)]\tLoss: 13.011126\n",
      "Train Epoch: 86 [448/720 (61%)]\tLoss: 13.526991\n",
      "Train Epoch: 86 [512/720 (70%)]\tLoss: 13.528593\n",
      "Train Epoch: 86 [576/720 (78%)]\tLoss: 11.475702\n",
      "Train Epoch: 86 [640/720 (87%)]\tLoss: 12.864633\n",
      "Train Epoch: 86 [352/720 (96%)]\tLoss: 10.944464\n",
      "====> Epoch: 86 Average loss: 12.1250\n",
      "====> Test set loss: 14.6758\n",
      "Train Epoch: 87 [0/720 (0%)]\tLoss: 12.305108\n",
      "Train Epoch: 87 [64/720 (9%)]\tLoss: 10.718848\n",
      "Train Epoch: 87 [128/720 (17%)]\tLoss: 13.087749\n",
      "Train Epoch: 87 [192/720 (26%)]\tLoss: 13.565232\n",
      "Train Epoch: 87 [256/720 (35%)]\tLoss: 12.614042\n",
      "Train Epoch: 87 [320/720 (43%)]\tLoss: 14.179199\n",
      "Train Epoch: 87 [384/720 (52%)]\tLoss: 13.482092\n",
      "Train Epoch: 87 [448/720 (61%)]\tLoss: 10.568067\n",
      "Train Epoch: 87 [512/720 (70%)]\tLoss: 12.202313\n",
      "Train Epoch: 87 [576/720 (78%)]\tLoss: 13.601295\n",
      "Train Epoch: 87 [640/720 (87%)]\tLoss: 11.770675\n",
      "Train Epoch: 87 [352/720 (96%)]\tLoss: 11.139407\n",
      "====> Epoch: 87 Average loss: 12.0901\n",
      "====> Test set loss: 14.8091\n",
      "Train Epoch: 88 [0/720 (0%)]\tLoss: 10.312767\n",
      "Train Epoch: 88 [64/720 (9%)]\tLoss: 12.207619\n",
      "Train Epoch: 88 [128/720 (17%)]\tLoss: 11.215585\n",
      "Train Epoch: 88 [192/720 (26%)]\tLoss: 11.354993\n",
      "Train Epoch: 88 [256/720 (35%)]\tLoss: 11.773154\n",
      "Train Epoch: 88 [320/720 (43%)]\tLoss: 11.195142\n",
      "Train Epoch: 88 [384/720 (52%)]\tLoss: 13.524293\n",
      "Train Epoch: 88 [448/720 (61%)]\tLoss: 12.686648\n",
      "Train Epoch: 88 [512/720 (70%)]\tLoss: 12.097613\n",
      "Train Epoch: 88 [576/720 (78%)]\tLoss: 14.744563\n",
      "Train Epoch: 88 [640/720 (87%)]\tLoss: 11.421508\n",
      "Train Epoch: 88 [352/720 (96%)]\tLoss: 12.372093\n",
      "====> Epoch: 88 Average loss: 12.1495\n",
      "====> Test set loss: 14.6966\n",
      "Train Epoch: 89 [0/720 (0%)]\tLoss: 12.675196\n",
      "Train Epoch: 89 [64/720 (9%)]\tLoss: 11.477936\n",
      "Train Epoch: 89 [128/720 (17%)]\tLoss: 11.020159\n",
      "Train Epoch: 89 [192/720 (26%)]\tLoss: 12.205581\n",
      "Train Epoch: 89 [256/720 (35%)]\tLoss: 12.861398\n",
      "Train Epoch: 89 [320/720 (43%)]\tLoss: 12.196107\n",
      "Train Epoch: 89 [384/720 (52%)]\tLoss: 10.802542\n",
      "Train Epoch: 89 [448/720 (61%)]\tLoss: 11.759681\n",
      "Train Epoch: 89 [512/720 (70%)]\tLoss: 11.949659\n",
      "Train Epoch: 89 [576/720 (78%)]\tLoss: 11.475781\n",
      "Train Epoch: 89 [640/720 (87%)]\tLoss: 12.753145\n",
      "Train Epoch: 89 [352/720 (96%)]\tLoss: 9.835197\n",
      "====> Epoch: 89 Average loss: 12.0847\n",
      "====> Test set loss: 14.7075\n",
      "Train Epoch: 90 [0/720 (0%)]\tLoss: 13.908520\n",
      "Train Epoch: 90 [64/720 (9%)]\tLoss: 11.995560\n",
      "Train Epoch: 90 [128/720 (17%)]\tLoss: 10.643721\n",
      "Train Epoch: 90 [192/720 (26%)]\tLoss: 10.700043\n",
      "Train Epoch: 90 [256/720 (35%)]\tLoss: 13.240112\n",
      "Train Epoch: 90 [320/720 (43%)]\tLoss: 11.005461\n",
      "Train Epoch: 90 [384/720 (52%)]\tLoss: 11.828467\n",
      "Train Epoch: 90 [448/720 (61%)]\tLoss: 11.748797\n",
      "Train Epoch: 90 [512/720 (70%)]\tLoss: 10.683759\n",
      "Train Epoch: 90 [576/720 (78%)]\tLoss: 12.855317\n",
      "Train Epoch: 90 [640/720 (87%)]\tLoss: 12.275605\n",
      "Train Epoch: 90 [352/720 (96%)]\tLoss: 10.712526\n",
      "====> Epoch: 90 Average loss: 12.0670\n",
      "====> Test set loss: 14.6697\n",
      "Train Epoch: 91 [0/720 (0%)]\tLoss: 12.726295\n",
      "Train Epoch: 91 [64/720 (9%)]\tLoss: 14.274781\n",
      "Train Epoch: 91 [128/720 (17%)]\tLoss: 11.207982\n",
      "Train Epoch: 91 [192/720 (26%)]\tLoss: 11.024889\n",
      "Train Epoch: 91 [256/720 (35%)]\tLoss: 11.997602\n",
      "Train Epoch: 91 [320/720 (43%)]\tLoss: 12.298523\n",
      "Train Epoch: 91 [384/720 (52%)]\tLoss: 12.600955\n",
      "Train Epoch: 91 [448/720 (61%)]\tLoss: 14.683370\n",
      "Train Epoch: 91 [512/720 (70%)]\tLoss: 13.614714\n",
      "Train Epoch: 91 [576/720 (78%)]\tLoss: 11.266877\n",
      "Train Epoch: 91 [640/720 (87%)]\tLoss: 12.468345\n",
      "Train Epoch: 91 [352/720 (96%)]\tLoss: 9.944668\n",
      "====> Epoch: 91 Average loss: 12.1014\n",
      "====> Test set loss: 14.7447\n",
      "Train Epoch: 92 [0/720 (0%)]\tLoss: 13.928153\n",
      "Train Epoch: 92 [64/720 (9%)]\tLoss: 10.212526\n",
      "Train Epoch: 92 [128/720 (17%)]\tLoss: 12.017904\n",
      "Train Epoch: 92 [192/720 (26%)]\tLoss: 11.841563\n",
      "Train Epoch: 92 [256/720 (35%)]\tLoss: 10.075937\n",
      "Train Epoch: 92 [320/720 (43%)]\tLoss: 12.839355\n",
      "Train Epoch: 92 [384/720 (52%)]\tLoss: 12.579132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 92 [448/720 (61%)]\tLoss: 11.780189\n",
      "Train Epoch: 92 [512/720 (70%)]\tLoss: 11.075782\n",
      "Train Epoch: 92 [576/720 (78%)]\tLoss: 13.386102\n",
      "Train Epoch: 92 [640/720 (87%)]\tLoss: 11.418207\n",
      "Train Epoch: 92 [352/720 (96%)]\tLoss: 15.707922\n",
      "====> Epoch: 92 Average loss: 12.0866\n",
      "====> Test set loss: 14.6550\n",
      "Train Epoch: 93 [0/720 (0%)]\tLoss: 16.499165\n",
      "Train Epoch: 93 [64/720 (9%)]\tLoss: 10.614902\n",
      "Train Epoch: 93 [128/720 (17%)]\tLoss: 12.192907\n",
      "Train Epoch: 93 [192/720 (26%)]\tLoss: 12.888800\n",
      "Train Epoch: 93 [256/720 (35%)]\tLoss: 12.080653\n",
      "Train Epoch: 93 [320/720 (43%)]\tLoss: 10.650553\n",
      "Train Epoch: 93 [384/720 (52%)]\tLoss: 13.273406\n",
      "Train Epoch: 93 [448/720 (61%)]\tLoss: 14.092139\n",
      "Train Epoch: 93 [512/720 (70%)]\tLoss: 11.609072\n",
      "Train Epoch: 93 [576/720 (78%)]\tLoss: 12.869329\n",
      "Train Epoch: 93 [640/720 (87%)]\tLoss: 10.772937\n",
      "Train Epoch: 93 [352/720 (96%)]\tLoss: 10.159099\n",
      "====> Epoch: 93 Average loss: 12.0540\n",
      "====> Test set loss: 14.6352\n",
      "Train Epoch: 94 [0/720 (0%)]\tLoss: 10.764151\n",
      "Train Epoch: 94 [64/720 (9%)]\tLoss: 12.593558\n",
      "Train Epoch: 94 [128/720 (17%)]\tLoss: 11.286323\n",
      "Train Epoch: 94 [192/720 (26%)]\tLoss: 11.059541\n",
      "Train Epoch: 94 [256/720 (35%)]\tLoss: 11.727646\n",
      "Train Epoch: 94 [320/720 (43%)]\tLoss: 12.612776\n",
      "Train Epoch: 94 [384/720 (52%)]\tLoss: 10.443222\n",
      "Train Epoch: 94 [448/720 (61%)]\tLoss: 12.956051\n",
      "Train Epoch: 94 [512/720 (70%)]\tLoss: 11.025940\n",
      "Train Epoch: 94 [576/720 (78%)]\tLoss: 12.140453\n",
      "Train Epoch: 94 [640/720 (87%)]\tLoss: 9.828186\n",
      "Train Epoch: 94 [352/720 (96%)]\tLoss: 11.747375\n",
      "====> Epoch: 94 Average loss: 12.0907\n",
      "====> Test set loss: 14.7323\n",
      "Train Epoch: 95 [0/720 (0%)]\tLoss: 12.699833\n",
      "Train Epoch: 95 [64/720 (9%)]\tLoss: 11.883697\n",
      "Train Epoch: 95 [128/720 (17%)]\tLoss: 12.688759\n",
      "Train Epoch: 95 [192/720 (26%)]\tLoss: 11.931548\n",
      "Train Epoch: 95 [256/720 (35%)]\tLoss: 12.406981\n",
      "Train Epoch: 95 [320/720 (43%)]\tLoss: 13.478355\n",
      "Train Epoch: 95 [384/720 (52%)]\tLoss: 13.782717\n",
      "Train Epoch: 95 [448/720 (61%)]\tLoss: 9.203172\n",
      "Train Epoch: 95 [512/720 (70%)]\tLoss: 12.617467\n",
      "Train Epoch: 95 [576/720 (78%)]\tLoss: 11.655925\n",
      "Train Epoch: 95 [640/720 (87%)]\tLoss: 11.036018\n",
      "Train Epoch: 95 [352/720 (96%)]\tLoss: 13.979595\n",
      "====> Epoch: 95 Average loss: 12.0512\n",
      "====> Test set loss: 14.6501\n",
      "Train Epoch: 96 [0/720 (0%)]\tLoss: 13.344239\n",
      "Train Epoch: 96 [64/720 (9%)]\tLoss: 10.831141\n",
      "Train Epoch: 96 [128/720 (17%)]\tLoss: 12.230433\n",
      "Train Epoch: 96 [192/720 (26%)]\tLoss: 12.131293\n",
      "Train Epoch: 96 [256/720 (35%)]\tLoss: 12.211396\n",
      "Train Epoch: 96 [320/720 (43%)]\tLoss: 12.033820\n",
      "Train Epoch: 96 [384/720 (52%)]\tLoss: 13.383438\n",
      "Train Epoch: 96 [448/720 (61%)]\tLoss: 10.973448\n",
      "Train Epoch: 96 [512/720 (70%)]\tLoss: 11.055209\n",
      "Train Epoch: 96 [576/720 (78%)]\tLoss: 10.681341\n",
      "Train Epoch: 96 [640/720 (87%)]\tLoss: 12.527216\n",
      "Train Epoch: 96 [352/720 (96%)]\tLoss: 10.310057\n",
      "====> Epoch: 96 Average loss: 11.9958\n",
      "====> Test set loss: 14.8117\n",
      "Train Epoch: 97 [0/720 (0%)]\tLoss: 11.761580\n",
      "Train Epoch: 97 [64/720 (9%)]\tLoss: 13.107068\n",
      "Train Epoch: 97 [128/720 (17%)]\tLoss: 12.674393\n",
      "Train Epoch: 97 [192/720 (26%)]\tLoss: 11.747061\n",
      "Train Epoch: 97 [256/720 (35%)]\tLoss: 11.319312\n",
      "Train Epoch: 97 [320/720 (43%)]\tLoss: 11.817698\n",
      "Train Epoch: 97 [384/720 (52%)]\tLoss: 10.275861\n",
      "Train Epoch: 97 [448/720 (61%)]\tLoss: 12.212453\n",
      "Train Epoch: 97 [512/720 (70%)]\tLoss: 13.878281\n",
      "Train Epoch: 97 [576/720 (78%)]\tLoss: 12.127331\n",
      "Train Epoch: 97 [640/720 (87%)]\tLoss: 12.728557\n",
      "Train Epoch: 97 [352/720 (96%)]\tLoss: 12.644517\n",
      "====> Epoch: 97 Average loss: 12.0329\n",
      "====> Test set loss: 14.7298\n",
      "Train Epoch: 98 [0/720 (0%)]\tLoss: 11.230310\n",
      "Train Epoch: 98 [64/720 (9%)]\tLoss: 13.070636\n",
      "Train Epoch: 98 [128/720 (17%)]\tLoss: 11.537939\n",
      "Train Epoch: 98 [192/720 (26%)]\tLoss: 10.774278\n",
      "Train Epoch: 98 [256/720 (35%)]\tLoss: 13.434146\n",
      "Train Epoch: 98 [320/720 (43%)]\tLoss: 13.854074\n",
      "Train Epoch: 98 [384/720 (52%)]\tLoss: 11.550219\n",
      "Train Epoch: 98 [448/720 (61%)]\tLoss: 11.290135\n",
      "Train Epoch: 98 [512/720 (70%)]\tLoss: 11.752986\n",
      "Train Epoch: 98 [576/720 (78%)]\tLoss: 12.153511\n",
      "Train Epoch: 98 [640/720 (87%)]\tLoss: 12.181016\n",
      "Train Epoch: 98 [352/720 (96%)]\tLoss: 14.615653\n",
      "====> Epoch: 98 Average loss: 12.0450\n",
      "====> Test set loss: 14.7562\n",
      "Train Epoch: 99 [0/720 (0%)]\tLoss: 12.040232\n",
      "Train Epoch: 99 [64/720 (9%)]\tLoss: 12.216012\n",
      "Train Epoch: 99 [128/720 (17%)]\tLoss: 12.382924\n",
      "Train Epoch: 99 [192/720 (26%)]\tLoss: 10.159951\n",
      "Train Epoch: 99 [256/720 (35%)]\tLoss: 13.682479\n",
      "Train Epoch: 99 [320/720 (43%)]\tLoss: 11.194370\n",
      "Train Epoch: 99 [384/720 (52%)]\tLoss: 12.715320\n",
      "Train Epoch: 99 [448/720 (61%)]\tLoss: 10.910451\n",
      "Train Epoch: 99 [512/720 (70%)]\tLoss: 11.805534\n",
      "Train Epoch: 99 [576/720 (78%)]\tLoss: 12.780852\n",
      "Train Epoch: 99 [640/720 (87%)]\tLoss: 12.651294\n",
      "Train Epoch: 99 [352/720 (96%)]\tLoss: 14.446733\n",
      "====> Epoch: 99 Average loss: 12.0330\n",
      "====> Test set loss: 14.7962\n",
      "Train Epoch: 100 [0/720 (0%)]\tLoss: 12.353537\n",
      "Train Epoch: 100 [64/720 (9%)]\tLoss: 12.111407\n",
      "Train Epoch: 100 [128/720 (17%)]\tLoss: 11.452919\n",
      "Train Epoch: 100 [192/720 (26%)]\tLoss: 12.035280\n",
      "Train Epoch: 100 [256/720 (35%)]\tLoss: 11.913588\n",
      "Train Epoch: 100 [320/720 (43%)]\tLoss: 12.181888\n",
      "Train Epoch: 100 [384/720 (52%)]\tLoss: 12.139976\n",
      "Train Epoch: 100 [448/720 (61%)]\tLoss: 11.500941\n",
      "Train Epoch: 100 [512/720 (70%)]\tLoss: 11.125319\n",
      "Train Epoch: 100 [576/720 (78%)]\tLoss: 13.671674\n",
      "Train Epoch: 100 [640/720 (87%)]\tLoss: 10.526931\n",
      "Train Epoch: 100 [352/720 (96%)]\tLoss: 10.221348\n",
      "====> Epoch: 100 Average loss: 12.0214\n",
      "====> Test set loss: 14.6819\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100 + 1):\n",
    "        train(epoch)\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebd9e4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1048576/128/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35dc7e81",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [32, 3, 4, 4], but got 3-dimensional input of size [8, 3, 16384] instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-21-97b917284364>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m128\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mrecon_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogvar\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecon_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogvar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-15-729e975db2b3>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 45\u001B[0;31m         \u001B[0mencoded\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     46\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m         \u001B[0;31m# sample latent code z from q given x.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 139\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    140\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 139\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    140\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 443\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    437\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[0;32m--> 439\u001B[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[1;32m    440\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected 4-dimensional input for 4-dimensional weight [32, 3, 4, 4], but got 3-dimensional input of size [8, 3, 16384] instead"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = 0\n",
    "for batch_idx,( data, _) in enumerate(train_loader):\n",
    "    data = data.to(device)\n",
    "    data = data.reshape([-1,3, 128*128])\n",
    "    optimizer.zero_grad()\n",
    "    recon_batch, mu, logvar = model(data)\n",
    "    loss = loss_function(recon_batch, data, mu, logvar)\n",
    "    loss.backward()\n",
    "    train_loss += loss.item()\n",
    "    optimizer.step()\n",
    "    if batch_idx % 100 == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader),\n",
    "            loss.item() / len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330af5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}